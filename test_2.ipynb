{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-Digit Alignment Using Template Matching\n",
    "\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from pytorch_msssim import ssim\n",
    "import torch.nn.functional as F\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from PIL import Image\n",
    "\n",
    "# Target alpha and beta values\n",
    "target_alpha = 88\n",
    "target_beta = 2\n",
    "\n",
    "# Directory containing metadata files and images\n",
    "data_dir = \"data/full_grid\"\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Set the MLflow experiment and load the model\n",
    "mlflow.set_experiment('Unet')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name('Unet')\n",
    "\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "run_id = runs[0].info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(f\"Model loaded from run {run_id} in experiment '{experiment.name}' successfully.\")\n",
    "\n",
    "# Define PSNR calculation\n",
    "def calculate_psnr(outputs, targets):\n",
    "    mse = F.mse_loss(outputs, targets)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * torch.log10(1 / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "# Transform to convert PIL image to tensor in [0,1]\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# Scan metadata files\n",
    "metadata_files = [f for f in os.listdir(data_dir) if f.startswith('metadata_') and f.endswith('.json')]\n",
    "found_file = None\n",
    "\n",
    "# Find matching alpha and beta\n",
    "for meta_file in metadata_files:\n",
    "    meta_path = os.path.join(data_dir, meta_file)\n",
    "    with open(meta_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    if metadata.get('alpha') == target_alpha and metadata.get('beta') == target_beta:\n",
    "        found_file = {\n",
    "            \"metadata_file\": meta_file,\n",
    "            \"index\": metadata.get('idx'),\n",
    "            \"digit_bboxes\": metadata.get('digit_bboxes'),\n",
    "            \"plate_number\": metadata.get('plate_number')\n",
    "        }\n",
    "        break\n",
    "\n",
    "print(f\"Found metadata file: {found_file['metadata_file']}\")\n",
    "print(f\"Alpha: {target_alpha}, Beta: {target_beta}\")\n",
    "print(f\"Plate Number: {found_file['plate_number']}\")\n",
    "\n",
    "# Sort bounding boxes\n",
    "original_bboxes = sorted(found_file['digit_bboxes'], key=lambda bbox: bbox[0])\n",
    "\n",
    "# Load images\n",
    "original_image_path = os.path.join(data_dir, f\"original_{found_file['index']}.png\")\n",
    "distorted_image_path = os.path.join(data_dir, f\"distorted_{found_file['index']}.png\")\n",
    "\n",
    "original_img = to_tensor(Image.open(original_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "distorted_img = to_tensor(Image.open(distorted_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    reconstructed_tensor = model(distorted_img)\n",
    "    reconstructed_tensor = torch.clamp(reconstructed_tensor, 0.0, 1.0)\n",
    "\n",
    "# Convert to NumPy\n",
    "original_np = original_img.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "reconstructed_np = reconstructed_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "# Align and update bounding boxes for the reconstructed image\n",
    "def align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes):\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    updated_bboxes = []\n",
    "    search_margin = 10\n",
    "\n",
    "    for bbox in digit_bboxes:\n",
    "        x, y, w, h = bbox\n",
    "\n",
    "        # Extract original digit\n",
    "        original_digit = original_np[y:y+h, x:x+w, :]\n",
    "        original_digit_gray = cv2.cvtColor((original_digit * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Define search window\n",
    "        search_x1 = max(0, x - search_margin)\n",
    "        search_y1 = max(0, y - search_margin)\n",
    "        search_x2 = min(reconstructed_np.shape[1], x + w + search_margin)\n",
    "        search_y2 = min(reconstructed_np.shape[0], y + h + search_margin)\n",
    "        search_region = reconstructed_np[search_y1:search_y2, search_x1:search_x2, :]\n",
    "        search_region_gray = cv2.cvtColor((search_region * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Template matching\n",
    "        result = cv2.matchTemplate(search_region_gray, original_digit_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        best_x, best_y = max_loc[0] + search_x1, max_loc[1] + search_y1\n",
    "\n",
    "        updated_bboxes.append((best_x, best_y, w, h))\n",
    "\n",
    "        # Extract aligned digit\n",
    "        aligned_digit = reconstructed_np[best_y:best_y+h, best_x:best_x+w, :]\n",
    "        original_digit_tensor = torch.from_numpy(original_digit.transpose(2, 0, 1)).unsqueeze(0).to(device)\n",
    "        aligned_digit_tensor = torch.from_numpy(aligned_digit.transpose(2, 0, 1)).unsqueeze(0).to(device)\n",
    "\n",
    "        # Compute metrics\n",
    "        psnr_val = calculate_psnr(aligned_digit_tensor, original_digit_tensor)\n",
    "        ssim_val = ssim(aligned_digit_tensor, original_digit_tensor, data_range=1.0, size_average=True).item()\n",
    "        psnr_values.append(psnr_val)\n",
    "        ssim_values.append(ssim_val)\n",
    "\n",
    "    return psnr_values, ssim_values, updated_bboxes\n",
    "\n",
    "# Perform alignment\n",
    "psnr_per_number, ssim_per_number, updated_bboxes = align_and_update_bboxes(original_np, reconstructed_np, original_bboxes)\n",
    "\n",
    "# Visualization\n",
    "reconstructed_show = (reconstructed_np * 255).astype(np.uint8)\n",
    "reconstructed_show = cv2.cvtColor(reconstructed_show, cv2.COLOR_RGB2BGR)\n",
    "original_image_cv = cv2.imread(original_image_path)\n",
    "\n",
    "# Draw original bounding boxes\n",
    "for i, bbox in enumerate(original_bboxes, start=1):\n",
    "    x, y, w, h = bbox\n",
    "    cv2.rectangle(original_image_cv, (x, y), (x+w, y+h), (0, 0, 255), 1)\n",
    "    cv2.putText(original_image_cv, str(i), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "\n",
    "# Draw updated bounding boxes on reconstructed image\n",
    "for i, bbox in enumerate(updated_bboxes, start=1):\n",
    "    x, y, w, h = bbox\n",
    "    cv2.rectangle(reconstructed_show, (x, y), (x+w, y+h), (0, 0, 255), 1)\n",
    "    cv2.putText(reconstructed_show, str(i), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "\n",
    "original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "reconstructed_image_rgb = cv2.cvtColor(reconstructed_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Prepare table\n",
    "table_data = [[\"Digit\", \"PSNR(dB)\", \"SSIM\"]]\n",
    "for i, (psnr_val, ssim_val) in enumerate(zip(psnr_per_number, ssim_per_number), start=1):\n",
    "    table_data.append([str(i), f\"{psnr_val:.2f}\", f\"{ssim_val:.3f}\"])\n",
    "transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(original_image_rgb)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(reconstructed_image_rgb)\n",
    "plt.title('Reconstructed Image')\n",
    "plt.axis('off')\n",
    "\n",
    "table = plt.table(cellText=transposed_table_data,\n",
    "                  cellLoc='center',\n",
    "                  loc='center',\n",
    "                  bbox=[0, -0.55, 1, 0.4])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best PSNR Selection with Template Matching\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import sys\n",
    "import cv2\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "# -----------------------------------\n",
    "# Configuration\n",
    "# -----------------------------------\n",
    "data_dir = \"data/full_grid\"\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# -----------------------------------\n",
    "# Load Model\n",
    "# -----------------------------------\n",
    "mlflow.set_experiment('Unet')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name('Unet')\n",
    "runs = client.search_runs(experiment_ids=experiment.experiment_id, order_by=[\"attributes.start_time DESC\"])\n",
    "run_id = runs[0].info.run_id  # Get the last run\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(f\"Model loaded from run {run_id} in experiment {experiment.name}\")\n",
    "\n",
    "def calculate_psnr(outputs, targets):\n",
    "    \"\"\"Calculate PSNR between two [0,1] tensor images using PyTorch functions.\"\"\"\n",
    "    mse = F.mse_loss(outputs, targets)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * torch.log10(1 / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# Function to align and update bboxes using template matching per digit\n",
    "def align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes):\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    updated_bboxes = []\n",
    "    search_margin = 10\n",
    "\n",
    "    for bbox in digit_bboxes:\n",
    "        x, y, w, h = bbox\n",
    "\n",
    "        # Extract original digit\n",
    "        original_digit = original_np[y:y+h, x:x+w, :]\n",
    "        original_digit_gray = cv2.cvtColor((original_digit * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Define search window in reconstructed image\n",
    "        search_x1 = max(0, x - search_margin)\n",
    "        search_y1 = max(0, y - search_margin)\n",
    "        search_x2 = min(reconstructed_np.shape[1], x + w + search_margin)\n",
    "        search_y2 = min(reconstructed_np.shape[0], y + h + search_margin)\n",
    "        search_region = reconstructed_np[search_y1:search_y2, search_x1:search_x2, :]\n",
    "        search_region_gray = cv2.cvtColor((search_region * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Template matching\n",
    "        result = cv2.matchTemplate(search_region_gray, original_digit_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        best_x, best_y = max_loc[0] + search_x1, max_loc[1] + search_y1\n",
    "\n",
    "        updated_bboxes.append((best_x, best_y, w, h))\n",
    "\n",
    "        # Extract aligned digit\n",
    "        aligned_digit = reconstructed_np[best_y:best_y+h, best_x:best_x+w, :]\n",
    "        original_digit_tensor = torch.from_numpy(original_digit.transpose(2, 0, 1)).unsqueeze(0).to(device)\n",
    "        aligned_digit_tensor = torch.from_numpy(aligned_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "\n",
    "        # Compute metrics\n",
    "        psnr_val = calculate_psnr(aligned_digit_tensor, original_digit_tensor)\n",
    "        ssim_val = ssim(aligned_digit_tensor, original_digit_tensor, data_range=1.0, size_average=True).item()\n",
    "        psnr_values.append(psnr_val)\n",
    "        ssim_values.append(ssim_val)\n",
    "\n",
    "    return psnr_values, ssim_values, updated_bboxes\n",
    "\n",
    "# -----------------------------------\n",
    "# Compute PSNR Heatmap\n",
    "# -----------------------------------\n",
    "metadata_files = [f for f in os.listdir(data_dir) if f.startswith('metadata_') and f.endswith('.json')]\n",
    "\n",
    "psnr_dict_avg = {}\n",
    "psnr_dict_worst = {}\n",
    "\n",
    "for meta_file in tqdm(metadata_files, desc=\"Processing images\", unit=\"image\"):\n",
    "    meta_path = os.path.join(data_dir, meta_file)\n",
    "    with open(meta_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    alpha, beta, noise_level = metadata['alpha'], metadata['beta'], metadata['noise_level']\n",
    "    digit_bboxes = metadata['digit_bboxes']\n",
    "\n",
    "    idx = metadata['idx']\n",
    "    original_path = os.path.join(data_dir, f\"original_{idx}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{idx}.png\")\n",
    "\n",
    "    # Load images as tensors\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        reconstructed_img = model(distorted_img)\n",
    "        reconstructed_img = torch.clamp(reconstructed_img, 0, 1)\n",
    "\n",
    "    # Convert images to NumPy\n",
    "    original_np = original_img.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "    reconstructed_np = reconstructed_img.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "    # Apply template matching alignment per digit\n",
    "    psnr_per_number, ssim_per_number, updated_bboxes = align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes)\n",
    "    avg_psnr = np.mean(psnr_per_number) if psnr_per_number else 0\n",
    "    worst_psnr = min(psnr_per_number, default=0)\n",
    "\n",
    "    if (alpha, beta) not in psnr_dict_avg:\n",
    "        psnr_dict_avg[(alpha, beta)] = []\n",
    "        psnr_dict_worst[(alpha, beta)] = []\n",
    "    psnr_dict_avg[(alpha, beta)].append(avg_psnr)\n",
    "    psnr_dict_worst[(alpha, beta)].append(worst_psnr)\n",
    "\n",
    "# Average over multiple images if any\n",
    "for key in psnr_dict_avg:\n",
    "    psnr_dict_avg[key] = np.mean(psnr_dict_avg[key])\n",
    "    psnr_dict_worst[key] = np.mean(psnr_dict_worst[key])\n",
    "\n",
    "alpha_values = sorted(set(a for (a, b) in psnr_dict_avg.keys()))\n",
    "beta_values = sorted(set(b for (a, b) in psnr_dict_avg.keys()))\n",
    "num_alphas, num_betas = len(alpha_values), len(beta_values)\n",
    "\n",
    "psnr_matrix_avg = np.full((num_betas, num_alphas), np.nan)\n",
    "alpha_to_idx = {val: i for i, val in enumerate(alpha_values)}\n",
    "beta_to_idx = {val: i for i, val in enumerate(beta_values)}\n",
    "\n",
    "# Populate the PSNR matrix\n",
    "for (a, b), val in psnr_dict_avg.items():\n",
    "    psnr_matrix_avg[beta_to_idx[b], alpha_to_idx[a]] = val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show image details for a given alpha,beta function\n",
    "\n",
    "# -----------------------------------\n",
    "# Function to show image details for a given alpha,beta\n",
    "# Using the same template matching approach inside show_image_details_for\n",
    "# -----------------------------------\n",
    "def show_image_details_for(alpha, beta, data_dir, model, device):\n",
    "    metadata_files = [f for f in os.listdir(data_dir) if f.startswith('metadata_') and f.endswith('.json')]\n",
    "    found_file = None\n",
    "    for meta_file in metadata_files:\n",
    "        meta_path = os.path.join(data_dir, meta_file)\n",
    "        with open(meta_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        if metadata.get('alpha') == alpha and metadata.get('beta') == beta:\n",
    "            found_file = {\n",
    "                \"metadata_file\": meta_file,\n",
    "                \"index\": metadata.get('idx'),\n",
    "                \"digit_bboxes\": metadata.get('digit_bboxes'),\n",
    "                \"plate_number\": metadata.get('plate_number')\n",
    "            }\n",
    "            break\n",
    "\n",
    "    if found_file is None:\n",
    "        print(f\"No images found for alpha={alpha}, beta={beta}.\")\n",
    "        return\n",
    "\n",
    "    found_file['digit_bboxes'].sort(key=lambda bbox: bbox[0])\n",
    "\n",
    "    idx = found_file['index']\n",
    "    original_image_path = os.path.join(data_dir, f\"original_{idx}.png\")\n",
    "    distorted_image_path = os.path.join(data_dir, f\"distorted_{idx}.png\")\n",
    "\n",
    "    to_tensor = transforms.ToTensor()\n",
    "    original_img = to_tensor(Image.open(original_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        reconstructed_tensor = model(distorted_img)\n",
    "        reconstructed_tensor = torch.clamp(reconstructed_tensor, 0.0, 1.0)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    reconstructed_np = reconstructed_tensor.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    # Align and update bboxes with template matching\n",
    "    def calc_psnr_ssim(original_image, reconstructed_image, digit_bboxes):\n",
    "        # We'll reuse align_and_update_bboxes here to get aligned results\n",
    "        psnr_vals, ssim_vals, updated_bboxes = align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes)\n",
    "        return psnr_vals, ssim_vals, updated_bboxes\n",
    "\n",
    "    psnr_per_number, ssim_per_number, updated_bboxes = calc_psnr_ssim(original_img, reconstructed_tensor, found_file['digit_bboxes'])\n",
    "\n",
    "    reconstructed_show = (reconstructed_np * 255).astype(np.uint8)\n",
    "    reconstructed_show = cv2.cvtColor(reconstructed_show, cv2.COLOR_RGB2BGR)\n",
    "    original_image_cv = cv2.imread(original_image_path)\n",
    "\n",
    "    for i, bbox in enumerate(found_file['digit_bboxes'], start=1):\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(original_image_cv, (x, y), (x+w, y+h), (0, 0, 255), 1)\n",
    "        cv2.putText(original_image_cv, str(i), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "\n",
    "    for i, bbox in enumerate(updated_bboxes, start=1):\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(reconstructed_show, (x, y), (x+w, y+h), (0, 0, 255), 1)\n",
    "        cv2.putText(reconstructed_show, str(i), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "\n",
    "    original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "    reconstructed_image_rgb = cv2.cvtColor(reconstructed_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    table_data = [[\"Digit\", \"PSNR(dB)\", \"SSIM\"]]\n",
    "    for i, (p, s) in enumerate(zip(psnr_per_number, ssim_per_number), start=1):\n",
    "        table_data.append([str(i), f\"{p:.2f}\", f\"{s:.3f}\"])\n",
    "    transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "    fig2 = plt.figure(figsize=(14, 7))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.imshow(original_image_rgb)\n",
    "    plt.title(f'Original Image (Alpha={alpha}, Beta={beta})')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(reconstructed_image_rgb)\n",
    "    plt.title('Reconstructed Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    table = plt.table(cellText=transposed_table_data,\n",
    "                      cellLoc='center',\n",
    "                      loc='center',\n",
    "                      bbox=[0, -0.55, 1, 0.4])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -----------------------------------\n",
    "# Display Heatmap and Add Click Event\n",
    "# -----------------------------------\n",
    "plt.figure(figsize=(10, 8))\n",
    "im = plt.imshow(psnr_matrix_avg, origin='lower', aspect='auto', cmap=\"viridis\")\n",
    "plt.title(\"Average PSNR per Digit\")\n",
    "plt.colorbar(label='PSNR (dB)')\n",
    "plt.xticks(range(0, num_alphas, 5), alpha_values[::5])\n",
    "plt.yticks(range(0, num_betas, 5), beta_values[::5])\n",
    "plt.xlabel(\"Alpha (degrees)\")\n",
    "plt.ylabel(\"Beta (degrees)\")\n",
    "\n",
    "def format_coord(x, y):\n",
    "    col = int(round(x))\n",
    "    row = int(round(y))\n",
    "    if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "        alpha = alpha_values[col]\n",
    "        beta = beta_values[row]\n",
    "        psnr_value = psnr_matrix_avg[row, col]\n",
    "        return f\"Alpha: {alpha:.0f}, Beta: {beta:.0f}, PSNR: {psnr_value:.2f} dB\" if not np.isnan(psnr_value) else f\"Alpha: {alpha:.0f}, Beta: {beta:.0f}, PSNR: N/A\"\n",
    "    return \"Alpha: N/A, Beta: N/A\"\n",
    "\n",
    "plt.gca().format_coord = format_coord\n",
    "\n",
    "def on_click(event):\n",
    "    if event.inaxes == plt.gca():\n",
    "        x, y = event.xdata, event.ydata\n",
    "        if x is None or y is None:\n",
    "            return\n",
    "        col = int(round(x))\n",
    "        row = int(round(y))\n",
    "        if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "            alpha = alpha_values[col]\n",
    "            beta = beta_values[row]\n",
    "            show_image_details_for(alpha, beta, data_dir, model, device)\n",
    "\n",
    "plt.gcf().canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paddle OCR with Global Template Matching and Bounding Box Alignment\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from pytorch_msssim import ssim\n",
    "import torch.nn.functional as F\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Configuration\n",
    "# -----------------------------------------------------\n",
    "\n",
    "data_dir = \"data/full_grid\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize PaddleOCR (English, digits only, low confidence allowed)\n",
    "ocr = PaddleOCR(\n",
    "    use_angle_cls=False,  \n",
    "    lang='en',\n",
    "    use_space_char=False,\n",
    "    drop_score=0.1,\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Load Model via MLflow\n",
    "# -----------------------------------------------------\n",
    "mlflow.set_experiment('Unet')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name('Unet')\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "run_id = runs[0].info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print(f\"Model loaded from run {run_id} in experiment '{experiment.name}' successfully.\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Locate Metadata for Given Alpha, Beta\n",
    "# -----------------------------------------------------\n",
    "metadata_files = [f for f in os.listdir(data_dir) if f.startswith('metadata_') and f.endswith('.json')]\n",
    "found_file = None\n",
    "for meta_file in metadata_files:\n",
    "    meta_path = os.path.join(data_dir, meta_file)\n",
    "    with open(meta_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    if metadata.get('alpha') == target_alpha and metadata.get('beta') == target_beta:\n",
    "        found_file = {\n",
    "            \"metadata_file\": meta_file,\n",
    "            \"index\": metadata.get('idx'),\n",
    "            \"digit_bboxes\": metadata.get('digit_bboxes'),\n",
    "            \"plate_number\": metadata.get('plate_number')\n",
    "        }\n",
    "        break\n",
    "\n",
    "if not found_file:\n",
    "    print(\"No image found for given alpha, beta.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Found metadata file: {found_file['metadata_file']}\")\n",
    "print(f\"Alpha: {target_alpha}, Beta: {target_beta}\")\n",
    "print(f\"Plate Number: {found_file['plate_number']}\")\n",
    "\n",
    "# Sort original bboxes by x to ensure left-to-right order\n",
    "original_bboxes = sorted(found_file['digit_bboxes'], key=lambda bbox: bbox[0])\n",
    "\n",
    "original_image_path = os.path.join(data_dir, f\"original_{found_file['index']}.png\")\n",
    "distorted_image_path = os.path.join(data_dir, f\"distorted_{found_file['index']}.png\")\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "original_img = to_tensor(Image.open(original_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "distorted_img = to_tensor(Image.open(distorted_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    reconstructed_tensor = model(distorted_img)\n",
    "    reconstructed_tensor = torch.clamp(reconstructed_tensor, 0.0, 1.0)\n",
    "\n",
    "original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "reconstructed_np = reconstructed_tensor.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "\n",
    "def calculate_psnr(outputs, targets):\n",
    "    mse = F.mse_loss(outputs, targets)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * torch.log10(1 / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "def align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes):\n",
    "    \"\"\"\n",
    "    Template matching to find updated bounding boxes for each digit.\n",
    "    \"\"\"\n",
    "    from pytorch_msssim import ssim\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    updated_bboxes = []\n",
    "    search_margin = 10\n",
    "\n",
    "    for bbox in digit_bboxes:\n",
    "        x, y, w, h = bbox\n",
    "\n",
    "        original_digit = original_np[y:y+h, x:x+w, :]\n",
    "        original_digit_gray = cv2.cvtColor((original_digit * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        search_x1 = max(0, x - search_margin)\n",
    "        search_y1 = max(0, y - search_margin)\n",
    "        search_x2 = min(reconstructed_np.shape[1], x + w + search_margin)\n",
    "        search_y2 = min(reconstructed_np.shape[0], y + h + search_margin)\n",
    "        search_region = reconstructed_np[search_y1:search_y2, search_x1:search_x2, :]\n",
    "        search_region_gray = cv2.cvtColor((search_region * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        result = cv2.matchTemplate(search_region_gray, original_digit_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        best_x = max_loc[0] + search_x1\n",
    "        best_y = max_loc[1] + search_y1\n",
    "\n",
    "        updated_bboxes.append((best_x, best_y, w, h))\n",
    "\n",
    "        aligned_digit = reconstructed_np[best_y:best_y+h, best_x:best_x+w, :]\n",
    "        original_digit_tensor = torch.from_numpy(original_digit.transpose(2, 0, 1)).unsqueeze(0).to(device)\n",
    "        aligned_digit_tensor = torch.from_numpy(aligned_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "\n",
    "        psnr_val = calculate_psnr(aligned_digit_tensor, original_digit_tensor)\n",
    "        ssim_val = ssim(aligned_digit_tensor, original_digit_tensor, data_range=1.0, size_average=True).item()\n",
    "        psnr_values.append(psnr_val)\n",
    "        ssim_values.append(ssim_val)\n",
    "\n",
    "    return psnr_values, ssim_values, updated_bboxes\n",
    "\n",
    "psnr_per_number, ssim_per_number, updated_bboxes = align_and_update_bboxes(original_np, reconstructed_np, original_bboxes)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Run PaddleOCR on the reconstructed image\n",
    "# -----------------------------------------------------\n",
    "reconstructed_show = (reconstructed_np * 255).astype(np.uint8)\n",
    "reconstructed_show_bgr = cv2.cvtColor(reconstructed_show, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "ocr_results = ocr.ocr(reconstructed_show_bgr, cls=False)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Process OCR Results:\n",
    "# Filter digits only, and align them with updated_bboxes\n",
    "# -----------------------------------------------------\n",
    "def extract_digits_from_ocr(ocr_results):\n",
    "    \"\"\"\n",
    "    Extracts per-character bounding boxes for digits from PaddleOCR line results.\n",
    "    If a line says \"3163\" with one bounding box, we split horizontally.\n",
    "    Returns a list of dicts: {\"char\": c, \"bbox\": (x1,y1,x2,y2)} for each digit found.\n",
    "    \"\"\"\n",
    "    per_char_results = []\n",
    "\n",
    "    for line in ocr_results[0]:\n",
    "        box, (text, conf) = line\n",
    "        if not isinstance(text, str) or text.strip() == \"\":\n",
    "            continue\n",
    "        text = text.strip()\n",
    "\n",
    "        # Keep only digits from this text\n",
    "        filtered_text = \"\".join([ch for ch in text if ch.isdigit()])\n",
    "        if len(filtered_text) == 0:\n",
    "            continue\n",
    "\n",
    "        xs = [p[0] for p in box]\n",
    "        ys = [p[1] for p in box]\n",
    "        min_x, max_x = min(xs), max(xs)\n",
    "        min_y, max_y = min(ys), max(ys)\n",
    "\n",
    "        num_chars = len(text)\n",
    "        # We'll subdivide bounding box by number of characters to approximate char positions\n",
    "        # But we only consider digits. This means we must map digits back to their positions\n",
    "        # in the original text.\n",
    "\n",
    "        # Approach: for each character in text, assign a sub-box. Then only keep if it's a digit.\n",
    "        width = max_x - min_x\n",
    "        char_width = width / num_chars if num_chars > 0 else width\n",
    "\n",
    "        current_x = min_x\n",
    "        for i, ch in enumerate(text):\n",
    "            c_x1 = int(min_x + i * char_width)\n",
    "            c_x2 = int(min_x + (i+1)* char_width)\n",
    "            c_y1 = int(min_y)\n",
    "            c_y2 = int(max_y)\n",
    "\n",
    "            if ch.isdigit():\n",
    "                per_char_results.append({\n",
    "                    \"char\": ch,\n",
    "                    \"bbox\": (c_x1, c_y1, c_x2, c_y2)\n",
    "                })\n",
    "\n",
    "    return per_char_results\n",
    "\n",
    "char_results = []\n",
    "if ocr_results and len(ocr_results) > 0 and ocr_results[0] is not None:\n",
    "    char_results = extract_digits_from_ocr(ocr_results)\n",
    "\n",
    "# Sort recognized digits by x-coordinate\n",
    "char_results.sort(key=lambda r: r[\"bbox\"][0])  # sort by left x\n",
    "\n",
    "recognized_chars = [r[\"char\"] for r in char_results]\n",
    "recognized_text = \"\".join(recognized_chars)\n",
    "\n",
    "# We know we need exactly 6 digits:\n",
    "plate_number = found_file['plate_number']\n",
    "assert len(plate_number) == 6, \"Plate number must have exactly 6 digits\"\n",
    "\n",
    "# If we have more than 6 recognized digits, take only first 6 (leftmost)\n",
    "if len(recognized_chars) > 6:\n",
    "    recognized_chars = recognized_chars[:6]\n",
    "    char_results = char_results[:6]\n",
    "\n",
    "# If fewer than 6 digits recognized, fill missing with '?'\n",
    "if len(recognized_chars) < 6:\n",
    "    missing = 6 - len(recognized_chars)\n",
    "    recognized_chars.extend(['?'] * missing)\n",
    "\n",
    "final_recognized_text = \"\".join(recognized_chars[:6])\n",
    "\n",
    "# Compute accuracy:\n",
    "correct_digits = sum(1 for a, b in zip(plate_number, final_recognized_text) if a == b)\n",
    "accuracy = correct_digits / 6.0\n",
    "\n",
    "print(f\"\\nPlate Number (GT): {plate_number}\")\n",
    "print(f\"Recognized (final): {final_recognized_text}\")\n",
    "print(f\"OCR Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# Visualization\n",
    "# -----------------------------------------------------\n",
    "# Draw original bounding boxes on original image\n",
    "original_image_cv = cv2.imread(original_image_path)\n",
    "for i, bbox in enumerate(original_bboxes, start=1):\n",
    "    x, y, w, h = bbox\n",
    "    cv2.rectangle(original_image_cv, (x, y), (x+w, y+h), (0, 0, 255), 1)\n",
    "    cv2.putText(original_image_cv, str(i), (x, y-5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "\n",
    "# Draw updated bounding boxes on reconstructed image\n",
    "reconstructed_show_bgr = reconstructed_show_bgr.copy()\n",
    "for i, bbox in enumerate(updated_bboxes, start=1):\n",
    "    x, y, w, h = bbox\n",
    "    cv2.rectangle(reconstructed_show_bgr, (x, y), (x+w, y+h), (0, 0, 255), 1)\n",
    "    cv2.putText(reconstructed_show_bgr, str(i), (x, y-5),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "\n",
    "# Draw recognized characters on reconstructed image\n",
    "for r in char_results:\n",
    "    c = r[\"char\"]\n",
    "    x1, y1, x2, y2 = r[\"bbox\"]\n",
    "    cv2.rectangle(reconstructed_show_bgr, (x1,y1), (x2,y2), (0,255,0), 1)\n",
    "    cv2.putText(reconstructed_show_bgr, c, (x1,y1-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0),1)\n",
    "\n",
    "# Prepare table for PSNR, SSIM\n",
    "table_data = [[\"Digit\", \"PSNR(dB)\", \"SSIM\"]]\n",
    "for i, (psnr_val, ssim_val) in enumerate(zip(psnr_per_number, ssim_per_number), start=1):\n",
    "    table_data.append([str(i), f\"{psnr_val:.2f}\", f\"{ssim_val:.3f}\"])\n",
    "transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "reconstructed_image_rgb = cv2.cvtColor(reconstructed_show_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "fig = plt.figure(figsize=(14, 10))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.imshow(original_image_rgb)\n",
    "plt.title('Original Image with Original BBoxes')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(reconstructed_image_rgb)\n",
    "plt.title(f\"Reconstructed Image with Updated BBoxes and OCR Results\\nRecognized: {final_recognized_text}, Accuracy: {accuracy*100:.2f}%\")\n",
    "plt.axis('off')\n",
    "\n",
    "table = plt.table(cellText=transposed_table_data,\n",
    "                  cellLoc='center',\n",
    "                  loc='center',\n",
    "                  bbox=[0, -0.55, 1, 0.4])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "\n",
    "plt.subplots_adjust(left=0.2, bottom=0.3, top=0.9)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/05/03 13:07:04] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\stopc/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\stopc/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='digit_dict.txt', use_space_char=False, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='C:\\\\Users\\\\stopc/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "Model loaded from run d1760efe9d2c44b3a39b7fa186e22e03 in experiment 'Unet' successfully.\n",
      "Found metadata file: metadata_7831.json\n",
      "Alpha: 87, Beta: 1\n",
      "Plate Number: 521992\n",
      "\n",
      "Running OCR on region: x1=0, y1=0, x2=69, y2=64\n",
      "[2025/05/03 13:07:07] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.030916690826416016\n",
      "[2025/05/03 13:07:07] ppocr DEBUG: rec_res num  : 1, elapsed : 0.07679581642150879\n",
      "OCR Raw Results: [[[[[17.0, 9.0], [59.0, 10.0], [57.0, 56.0], [15.0, 55.0]], ('3', 0.7161337733268738)]]]\n",
      "  Detected: '3' (Confidence: 0.72)\n",
      "Final Recognized Digit: 3\n",
      "\n",
      "Running OCR on region: x1=37, y1=0, x2=110, y2=64\n",
      "[2025/05/03 13:07:07] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.016953706741333008\n",
      "Error during OCR: list index out of range\n",
      "\n",
      "Running OCR on region: x1=75, y1=0, x2=138, y2=64\n",
      "[2025/05/03 13:07:08] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.015956401824951172\n",
      "[2025/05/03 13:07:08] ppocr DEBUG: rec_res num  : 1, elapsed : 0.06283235549926758\n",
      "OCR Raw Results: [[[[[15.0, 23.0], [40.0, 23.0], [40.0, 44.0], [15.0, 44.0]], ('1', 0.16509796679019928)]]]\n",
      "  Detected: '1' (Confidence: 0.17)\n",
      "Final Recognized Digit: 1\n",
      "\n",
      "Running OCR on region: x1=106, y1=0, x2=178, y2=64\n",
      "[2025/05/03 13:07:08] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.01695418357849121\n",
      "[2025/05/03 13:07:08] ppocr DEBUG: rec_res num  : 1, elapsed : 0.05934953689575195\n",
      "OCR Raw Results: [[[[[7.0, 12.0], [57.0, 12.0], [57.0, 53.0], [7.0, 53.0]], ('9', 0.9264513850212097)]]]\n",
      "  Detected: '9' (Confidence: 0.93)\n",
      "Final Recognized Digit: 9\n",
      "\n",
      "Running OCR on region: x1=146, y1=0, x2=218, y2=64\n",
      "[2025/05/03 13:07:08] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.01695561408996582\n",
      "[2025/05/03 13:07:08] ppocr DEBUG: rec_res num  : 1, elapsed : 0.0857696533203125\n",
      "OCR Raw Results: [[[[[16.0, 11.0], [62.0, 11.0], [62.0, 54.0], [16.0, 54.0]], ('9', 0.9864361882209778)]]]\n",
      "  Detected: '9' (Confidence: 0.99)\n",
      "Final Recognized Digit: 9\n",
      "\n",
      "Running OCR on region: x1=185, y1=0, x2=256, y2=64\n",
      "[2025/05/03 13:07:08] ppocr DEBUG: dt_boxes num : 1, elapsed : 0.01595783233642578\n",
      "Error during OCR: list index out of range\n",
      "Recognized Digits (Left to Right): 3?199?\n",
      "OCR Accuracy: 50.00%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Per-Digit Paddle OCR with Template Matching and Margin Adjustment\n",
    "\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from paddleocr import PaddleOCR\n",
    "from pytorch_msssim import ssim\n",
    "import torch.nn.functional as F\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "# --------------------\n",
    "# Configuration\n",
    "# --------------------\n",
    "\n",
    "data_dir = \"data/full_grid\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "search_margin = 10  # Margin for template matching search\n",
    "ocr_margin = 25  # Margin around TMBB for OCR\n",
    "\n",
    "digit_dict = \"digit_dict.txt\"\n",
    "\n",
    "# Initialize PaddleOCR\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang=\"en\", rec_char_dict_path=digit_dict, use_space_char=False, drop_score=0)\n",
    "\n",
    "# --------------------\n",
    "# Load the Model\n",
    "# --------------------\n",
    "mlflow.set_experiment(\"Unet\")\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name(\"Unet\")\n",
    "runs = client.search_runs(experiment_ids=experiment.experiment_id, order_by=[\"attributes.start_time DESC\"])\n",
    "run_id = runs[0].info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval().to(device)\n",
    "\n",
    "print(f\"Model loaded from run {run_id} in experiment '{experiment.name}' successfully.\")\n",
    "\n",
    "\n",
    "def calculate_psnr(outputs, targets):\n",
    "    mse = F.mse_loss(outputs, targets)\n",
    "    if mse == 0:\n",
    "        return float(\"inf\")\n",
    "    psnr = 10 * torch.log10(1 / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Find Matching alpha, beta\n",
    "# --------------------\n",
    "metadata_files = [f for f in os.listdir(data_dir) if f.startswith(\"metadata_\") and f.endswith(\".json\")]\n",
    "found_file = None\n",
    "for meta_file in metadata_files:\n",
    "    meta_path = os.path.join(data_dir, meta_file)\n",
    "    with open(meta_path, \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "    if metadata.get(\"alpha\") == target_alpha and metadata.get(\"beta\") == target_beta:\n",
    "        found_file = {\n",
    "            \"metadata_file\": meta_file,\n",
    "            \"index\": metadata.get(\"idx\"),\n",
    "            \"digit_bboxes\": metadata.get(\"digit_bboxes\"),\n",
    "            \"plate_number\": metadata.get(\"plate_number\"),\n",
    "        }\n",
    "        break\n",
    "\n",
    "if not found_file:\n",
    "    print(\"Image with the specified alpha and beta not found.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Found metadata file: {found_file['metadata_file']}\")\n",
    "print(f\"Alpha: {target_alpha}, Beta: {target_beta}\")\n",
    "print(f\"Plate Number: {found_file['plate_number']}\")\n",
    "\n",
    "original_bboxes = sorted(found_file[\"digit_bboxes\"], key=lambda bbox: bbox[0])\n",
    "\n",
    "original_image_path = os.path.join(data_dir, f\"original_{found_file['index']}.png\")\n",
    "distorted_image_path = os.path.join(data_dir, f\"distorted_{found_file['index']}.png\")\n",
    "\n",
    "original_img = to_tensor(Image.open(original_image_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "distorted_img = to_tensor(Image.open(distorted_image_path).convert(\"RGB\")).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    reconstructed_tensor = model(distorted_img)\n",
    "    reconstructed_tensor = torch.clamp(reconstructed_tensor, 0.0, 1.0)\n",
    "\n",
    "original_np = original_img.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "reconstructed_np = reconstructed_tensor.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
    "\n",
    "\n",
    "def align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes):\n",
    "    from pytorch_msssim import ssim\n",
    "\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    updated_bboxes = []\n",
    "    for bbox in digit_bboxes:\n",
    "        x, y, w, h = bbox\n",
    "\n",
    "        original_digit = original_np[y : y + h, x : x + w, :]\n",
    "        original_digit_gray = cv2.cvtColor((original_digit * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Search region\n",
    "        search_x1 = max(0, x - search_margin)\n",
    "        search_y1 = max(0, y - search_margin)\n",
    "        search_x2 = min(reconstructed_np.shape[1], x + w + search_margin)\n",
    "        search_y2 = min(reconstructed_np.shape[0], y + h + search_margin)\n",
    "        search_region = reconstructed_np[search_y1:search_y2, search_x1:search_x2, :]\n",
    "        search_region_gray = cv2.cvtColor((search_region * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        result = cv2.matchTemplate(search_region_gray, original_digit_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        best_x, best_y = max_loc[0] + search_x1, max_loc[1] + search_y1\n",
    "\n",
    "        updated_bboxes.append((best_x, best_y, w, h))\n",
    "\n",
    "        aligned_digit = reconstructed_np[best_y : best_y + h, best_x : best_x + w, :]\n",
    "        original_digit_tensor = torch.from_numpy(original_digit.transpose(2, 0, 1)).unsqueeze(0).to(device)\n",
    "        aligned_digit_tensor = torch.from_numpy(aligned_digit.transpose(2, 0, 1)).unsqueeze(0).to(device)\n",
    "\n",
    "        psnr_val = calculate_psnr(aligned_digit_tensor, original_digit_tensor)\n",
    "        ssim_val = ssim(aligned_digit_tensor, original_digit_tensor, data_range=1.0, size_average=True).item()\n",
    "        psnr_values.append(psnr_val)\n",
    "        ssim_values.append(ssim_val)\n",
    "\n",
    "    return psnr_values, ssim_values, updated_bboxes\n",
    "\n",
    "\n",
    "psnr_per_number, ssim_per_number, updated_bboxes = align_and_update_bboxes(\n",
    "    original_np, reconstructed_np, original_bboxes\n",
    ")\n",
    "\n",
    "reconstructed_show = (reconstructed_np * 255).astype(np.uint8)\n",
    "reconstructed_show = cv2.cvtColor(reconstructed_show, cv2.COLOR_RGB2BGR)\n",
    "original_image_cv = cv2.imread(original_image_path)\n",
    "\n",
    "# Draw original bounding boxes\n",
    "for i, bbox in enumerate(original_bboxes, start=1):\n",
    "    x, y, w, h = bbox\n",
    "    cv2.rectangle(original_image_cv, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "    # cv2.putText(original_image_cv, str(i), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "\n",
    "# Draw updated bounding boxes on reconstructed image\n",
    "for i, bbox in enumerate(updated_bboxes, start=1):\n",
    "    x, y, w, h = bbox\n",
    "    cv2.rectangle(reconstructed_show, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "    # cv2.putText(reconstructed_show, str(i), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "\n",
    "original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "reconstructed_image_rgb = cv2.cvtColor(reconstructed_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Per-Digit OCR using TMBB and PaddleOCR\n",
    "# --------------------\n",
    "def run_ocr_on_digit(reconstructed_bgr, bbox, margin=5):\n",
    "    x, y, w, h = bbox\n",
    "    H, W, _ = reconstructed_bgr.shape\n",
    "    x1 = max(0, x - margin)\n",
    "    y1 = max(0, y - margin)\n",
    "    x2 = min(W, x + w + margin)\n",
    "    y2 = min(H, y + h + margin)\n",
    "\n",
    "    digit_roi = reconstructed_bgr[y1:y2, x1:x2]\n",
    "    if digit_roi.size == 0:\n",
    "        print(f\"Warning: Empty ROI for bbox {bbox}\")\n",
    "        return \"\"\n",
    "\n",
    "    print(f\"\\nRunning OCR on region: x1={x1}, y1={y1}, x2={x2}, y2={y2}\")\n",
    "\n",
    "    try:\n",
    "        ocr_results = ocr.ocr(digit_roi, cls=False)\n",
    "        print(f\"OCR Raw Results: {ocr_results}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OCR: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    recognized_digit = \"\"\n",
    "    if ocr_results and ocr_results[0]:\n",
    "        for line in ocr_results[0]:\n",
    "            box, text_data = line[0], line[1]\n",
    "            recognized_text, confidence = text_data\n",
    "            filtered = \"\".join(ch for ch in recognized_text if ch.isdigit())\n",
    "            if filtered:\n",
    "                recognized_digit = filtered[0]\n",
    "                print(f\"  Detected: '{recognized_digit}' (Confidence: {confidence:.2f})\")\n",
    "                break\n",
    "\n",
    "    if recognized_digit:\n",
    "        print(f\"Final Recognized Digit: {recognized_digit}\")\n",
    "    else:\n",
    "        print(\"No valid digits recognized.\")\n",
    "    return recognized_digit\n",
    "\n",
    "\n",
    "recognized_digits = []\n",
    "for i, bbox in enumerate(updated_bboxes, start=1):\n",
    "    digit = run_ocr_on_digit(reconstructed_show, bbox, margin=ocr_margin)\n",
    "    if not digit:\n",
    "        digit = \"?\"  # If no digit recognized, use placeholder\n",
    "    recognized_digits.append(digit)\n",
    "\n",
    "recognized_text = \"\".join(recognized_digits)\n",
    "ground_truth = found_file[\"plate_number\"]\n",
    "correct_digits = sum(1 for a, b in zip(ground_truth, recognized_text) if a == b)\n",
    "ocr_accuracy = correct_digits / len(ground_truth) if ground_truth else 0.0\n",
    "\n",
    "print(f\"Recognized Digits (Left to Right): {recognized_text}\")\n",
    "print(f\"OCR Accuracy: {ocr_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Draw per-digit OCR results\n",
    "for i, bbox in enumerate(updated_bboxes, start=1):\n",
    "    x, y, w, h = bbox\n",
    "    digit = recognized_digits[i - 1]\n",
    "    cv2.putText(reconstructed_image_rgb, digit, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "# --------------------\n",
    "# Visualization\n",
    "# --------------------\n",
    "table_data = [[\"Digit\", \"PSNR(dB)\", \"SSIM\"]]\n",
    "for i, (psnr_val, ssim_val) in enumerate(zip(psnr_per_number, ssim_per_number), start=1):\n",
    "    table_data.append([str(i), f\"{psnr_val:.2f}\", f\"{ssim_val:.3f}\"])\n",
    "transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(original_image_rgb)\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(reconstructed_image_rgb)\n",
    "plt.title(f\"Reconstructed Image - OCR: {recognized_text}, Accuracy: {ocr_accuracy*100:.2f}%\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "table = plt.table(cellText=transposed_table_data, cellLoc=\"center\", loc=\"center\", bbox=[0, -0.55, 1, 0.4])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_alpha = 87  # Target alpha\n",
    "target_beta = 1  # Target beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Image Analysis with Metadata Retrieval and Visualization\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import cv2\n",
    "from pytorch_msssim import ssim\n",
    "import pytesseract\n",
    "\n",
    "# --------------------\n",
    "# Configuration\n",
    "# --------------------\n",
    "data_dir = \"data/full_grid\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MLflow model load (if needed; assuming similar to Code 1)\n",
    "mlflow.set_experiment('Unet')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name('Unet')\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "run_id = runs[0].info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval().to(device)\n",
    "print(f\"Model loaded from run {run_id} in experiment '{experiment.name}' successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_alpha = 87  # Target alpha\n",
    "target_beta = 1  # Target beta\n",
    "# --------------------\n",
    "# Functions \n",
    "# --------------------\n",
    "\n",
    "def calculate_psnr(outputs, targets):\n",
    "    mse = F.mse_loss(outputs, targets)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * torch.log10(1 / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "def find_metadata(data_dir, target_alpha, target_beta):\n",
    "    \"\"\"\n",
    "    Find and return metadata for the specified alpha and beta.\n",
    "    \"\"\"\n",
    "    metadata_files = [f for f in os.listdir(data_dir) if f.startswith('metadata_') and f.endswith('.json')]\n",
    "    for meta_file in metadata_files:\n",
    "        meta_path = os.path.join(data_dir, meta_file)\n",
    "        with open(meta_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        if metadata.get('alpha') == target_alpha and metadata.get('beta') == target_beta:\n",
    "            return {\n",
    "                \"metadata_file\": meta_file,\n",
    "                \"index\": metadata.get('idx'),\n",
    "                \"digit_bboxes\": metadata.get('digit_bboxes'),\n",
    "                \"plate_number\": metadata.get('plate_number')\n",
    "            }\n",
    "    return None\n",
    "\n",
    "def align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes):\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    updated_bboxes = []\n",
    "    search_margin =  10\n",
    "\n",
    "    for bbox in digit_bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        original_digit = original_np[y:y+h, x:x+w, :]\n",
    "        original_digit_gray = cv2.cvtColor((original_digit * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Define search window\n",
    "        search_x1 = max(0, x - search_margin)\n",
    "        search_y1 = max(0, y - search_margin)\n",
    "        search_x2 = min(reconstructed_np.shape[1], x + w + search_margin)\n",
    "        search_y2 = min(reconstructed_np.shape[0], y + h + search_margin)\n",
    "        search_region = reconstructed_np[search_y1:search_y2, search_x1:search_x2, :]\n",
    "        search_region_gray = cv2.cvtColor((search_region * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Template matching\n",
    "        result = cv2.matchTemplate(search_region_gray, original_digit_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        best_x, best_y = max_loc[0] + search_x1, max_loc[1] + search_y1\n",
    "        updated_bboxes.append((best_x, best_y, w, h))\n",
    "\n",
    "        # Compute PSNR and SSIM\n",
    "        aligned_digit = reconstructed_np[best_y:best_y+h, best_x:best_x+w, :]\n",
    "        original_digit_tensor = torch.from_numpy(original_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "        aligned_digit_tensor = torch.from_numpy(aligned_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "\n",
    "        psnr_val = calculate_psnr(aligned_digit_tensor, original_digit_tensor)\n",
    "        ssim_val = ssim(aligned_digit_tensor, original_digit_tensor, data_range=1.0, size_average=True).item()\n",
    "        psnr_values.append(psnr_val)\n",
    "        ssim_values.append(ssim_val)\n",
    "\n",
    "    return psnr_values, ssim_values, updated_bboxes\n",
    "\n",
    "def ocr_single_digit(image_bgr):\n",
    "    \"\"\"\n",
    "    Recognize a single digit using Tesseract with single char mode and digit whitelist.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    config = r'--oem 3 --psm 10 -c tessedit_char_whitelist=0123456789'\n",
    "    text = pytesseract.image_to_string(thresh, config=config).strip()\n",
    "    if len(text) == 1 and text.isdigit():\n",
    "        return text\n",
    "    return '?'\n",
    "\n",
    "def compute_ocr_metrics(image_bgr, updated_bboxes, plate_number_gt, margin):\n",
    "    recognized_digits = []\n",
    "    for (x, y, w, h) in updated_bboxes:\n",
    "        x1 = max(0, x - margin)\n",
    "        y1 = max(0, y - margin)\n",
    "        x2 = min(image_bgr.shape[1], x + w + margin)\n",
    "        y2 = min(image_bgr.shape[0], y + h + margin)\n",
    "        \n",
    "        digit_patch = image_bgr[y1:y2, x1:x2]\n",
    "        recognized_digit = ocr_single_digit(digit_patch)\n",
    "        recognized_digits.append(recognized_digit)\n",
    "\n",
    "    recognized_text = \"\".join(recognized_digits)\n",
    "    gt = plate_number_gt\n",
    "    correct_digits = sum(1 for a, b in zip(gt, recognized_text) if a == b)\n",
    "    ocr_accuracy = correct_digits / len(gt) if len(gt) > 0 else 0.0\n",
    "    ocr_binary = 1.0 if recognized_text == gt else 0.0\n",
    "    return recognized_text, ocr_accuracy, ocr_binary\n",
    "\n",
    "# --------------------\n",
    "# Main Processing\n",
    "# --------------------\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "# Find metadata for the target alpha and beta\n",
    "found_file = find_metadata(data_dir, target_alpha, target_beta)\n",
    "\n",
    "if not found_file:\n",
    "    print(\"Image with the specified alpha and beta not found.\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Found metadata file: {found_file['metadata_file']}\")\n",
    "print(f\"Alpha: {target_alpha}, Beta: {target_beta}\")\n",
    "\n",
    "original_bboxes = found_file['digit_bboxes']\n",
    "\n",
    "original_image_path = os.path.join(data_dir, f\"original_{found_file['index']}.png\")\n",
    "distorted_image_path = os.path.join(data_dir, f\"distorted_{found_file['index']}.png\")\n",
    "\n",
    "if not (os.path.exists(original_image_path) and os.path.exists(distorted_image_path)):\n",
    "    print(\"Original or distorted image not found.\")\n",
    "    exit()\n",
    "\n",
    "original_img = to_tensor(Image.open(original_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "distorted_img = to_tensor(Image.open(distorted_image_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    reconstructed_tensor = model(distorted_img)\n",
    "    reconstructed_tensor = torch.clamp(reconstructed_tensor, 0.0, 1.0)\n",
    "\n",
    "original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "reconstructed_np = reconstructed_tensor.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "psnr_per_number, ssim_per_number, updated_bboxes = align_and_update_bboxes(original_np, reconstructed_np, original_bboxes)\n",
    "\n",
    "# Convert reconstructed to BGR for visualization\n",
    "reconstructed_show = (reconstructed_np * 255).astype(np.uint8)\n",
    "reconstructed_show = cv2.cvtColor(reconstructed_show, cv2.COLOR_RGB2BGR)\n",
    "original_image_cv = cv2.imread(original_image_path)\n",
    "\n",
    "# Draw original bounding boxes\n",
    "for i, bbox in enumerate(original_bboxes, start=1):\n",
    "    x, y, w, h = bbox\n",
    "    cv2.rectangle(original_image_cv, (x, y), (x+w, y+h), (0, 0, 255), 1)\n",
    "    #cv2.putText(original_image_cv, str(i), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "\n",
    "# Draw updated bounding boxes on reconstructed image\n",
    "for i, bbox in enumerate(updated_bboxes, start=1):\n",
    "    x, y, w, h = bbox\n",
    "    cv2.rectangle(reconstructed_show, (x, y), (x+w, y+h), (0, 0, 255), 1)\n",
    "    #cv2.putText(reconstructed_show, str(i), (x, y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 150, 0), 1)\n",
    "\n",
    "original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "reconstructed_image_rgb = cv2.cvtColor(reconstructed_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Perform OCR and compute metrics\n",
    "plate_number_gt = found_file['plate_number']\n",
    "recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(reconstructed_show, updated_bboxes, plate_number_gt, margin=2)\n",
    "\n",
    "# Prepare table data\n",
    "table_data = [[\"Digit\", \"PSNR(dB)\", \"SSIM\"]]\n",
    "for i, (psnr_val, ssim_val) in enumerate(zip(psnr_per_number, ssim_per_number), start=1):\n",
    "    table_data.append([str(i), f\"{psnr_val:.2f}\", f\"{ssim_val:.3f}\"])\n",
    "transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(original_image_rgb)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(reconstructed_image_rgb)\n",
    "plt.title(f'Reconstructed Image (alpha: {target_alpha}, beta: {target_beta})\\nGT: {plate_number_gt}, Recognized: {recognized_text}, Acc: {ocr_accuracy*100:.2f}%')\n",
    "plt.axis('off')\n",
    "\n",
    "table = plt.table(cellText=transposed_table_data,\n",
    "                    cellLoc='center',\n",
    "                    loc='center',\n",
    "                    bbox=[0, -0.55, 1, 0.4])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap Visualization of average PSNR, SSIM, and OCR Metrics with Interactive Analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import cv2\n",
    "from pytorch_msssim import ssim\n",
    "import pytesseract\n",
    "\n",
    "# --------------------\n",
    "# Configuration\n",
    "# --------------------\n",
    "data_dir = \"data_test\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MLflow model load\n",
    "mlflow.set_experiment('Unet')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name('Unet')\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "run_id = runs[0].info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval().to(device)\n",
    "print(f\"Model loaded from run {run_id} in experiment '{experiment.name}' successfully.\")\n",
    "\n",
    "def calculate_psnr(outputs, targets):\n",
    "    mse = F.mse_loss(outputs, targets)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * torch.log10(1 / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "def align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes):\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    updated_bboxes = []\n",
    "    search_margin = 10\n",
    "\n",
    "    for bbox in digit_bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        original_digit = original_np[y:y+h, x:x+w, :]\n",
    "        original_digit_gray = cv2.cvtColor((original_digit * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        search_x1 = max(0, x - search_margin)\n",
    "        search_y1 = max(0, y - search_margin)\n",
    "        search_x2 = min(reconstructed_np.shape[1], x + w + search_margin)\n",
    "        search_y2 = min(reconstructed_np.shape[0], y + h + search_margin)\n",
    "        search_region = reconstructed_np[search_y1:search_y2, search_x1:search_x2, :]\n",
    "        search_region_gray = cv2.cvtColor((search_region * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        result = cv2.matchTemplate(search_region_gray, original_digit_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        best_x, best_y = max_loc[0] + search_x1, max_loc[1] + search_y1\n",
    "        updated_bboxes.append((best_x, best_y, w, h))\n",
    "\n",
    "        aligned_digit = reconstructed_np[best_y:best_y+h, best_x:best_x+w, :]\n",
    "        original_digit_tensor = torch.from_numpy(original_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "        aligned_digit_tensor = torch.from_numpy(aligned_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "\n",
    "        psnr_val = calculate_psnr(aligned_digit_tensor, original_digit_tensor)\n",
    "        ssim_val = ssim(aligned_digit_tensor, original_digit_tensor, data_range=1.0, size_average=True).item()\n",
    "        psnr_values.append(psnr_val)\n",
    "        ssim_values.append(ssim_val)\n",
    "\n",
    "    return psnr_values, ssim_values, updated_bboxes\n",
    "\n",
    "def ocr_single_digit(image_bgr):\n",
    "    \"\"\"\n",
    "    Recognize a single digit using Tesseract with single char mode and digit whitelist.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    config = r'--oem 1 --psm 10 -c tessedit_char_whitelist=0123456789'\n",
    "    text = pytesseract.image_to_string(thresh, config=config).strip()\n",
    "    if len(text) == 1 and text.isdigit():\n",
    "        return text\n",
    "    return '?'\n",
    "\n",
    "def compute_ocr_metrics(reconstructed_bgr, updated_bboxes, plate_number_gt):\n",
    "    recognized_digits = []\n",
    "    M = 16\n",
    "    for (x, y, w, h) in updated_bboxes:\n",
    "        x1 = max(0, x - M)\n",
    "        y1 = max(0, y - M)\n",
    "        x2 = min(reconstructed_bgr.shape[1], x + w + M)\n",
    "        y2 = min(reconstructed_bgr.shape[0], y + h + M)\n",
    "        digit_patch = reconstructed_bgr[y1:y2, x1:x2]\n",
    "        recognized_digit = ocr_single_digit(digit_patch)\n",
    "        recognized_digits.append(recognized_digit)\n",
    "\n",
    "    recognized_text = \"\".join(recognized_digits)\n",
    "    gt = plate_number_gt\n",
    "    correct_digits = sum(1 for a, b in zip(gt, recognized_text) if a == b)\n",
    "    ocr_accuracy = correct_digits / len(gt) if len(gt) > 0 else 0.0\n",
    "    ocr_binary = 1.0 if recognized_text == gt else 0.0\n",
    "    return recognized_text, ocr_accuracy, ocr_binary\n",
    "\n",
    "# -----------------------------------\n",
    "# Compute metrics for each (alpha,beta)\n",
    "# -----------------------------------\n",
    "metadata_files = [f for f in os.listdir(data_dir) if f.startswith('metadata_') and f.endswith('.json')]\n",
    "\n",
    "psnr_dict_avg = {}\n",
    "ssim_dict_avg = {}\n",
    "ocr_acc_dict_avg = {}\n",
    "ocr_bin_dict_avg = {}\n",
    "\n",
    "for meta_file in tqdm(metadata_files, desc=\"Processing images\", unit=\"image\"):\n",
    "    meta_path = os.path.join(data_dir, meta_file)\n",
    "    with open(meta_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    alpha, beta = metadata['alpha'], metadata['beta']\n",
    "    digit_bboxes = metadata['digit_bboxes']\n",
    "    plate_number_gt = metadata['plate_number']\n",
    "\n",
    "    idx = metadata['idx']\n",
    "    original_path = os.path.join(data_dir, f\"original_{idx}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{idx}.png\")\n",
    "\n",
    "    if not (os.path.exists(original_path) and os.path.exists(distorted_path)):\n",
    "        continue\n",
    "\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        reconstructed_img = model(distorted_img)\n",
    "        reconstructed_img = torch.clamp(reconstructed_img, 0, 1)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    reconstructed_np = reconstructed_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    psnr_per_number, ssim_per_number, updated_bboxes = align_and_update_bboxes(original_np, reconstructed_np, digit_bboxes)\n",
    "    avg_psnr = np.mean(psnr_per_number) if psnr_per_number else 0.0\n",
    "    avg_ssim = np.mean(ssim_per_number) if ssim_per_number else 0.0\n",
    "\n",
    "    image_bgr = (reconstructed_np * 255).astype(np.uint8)\n",
    "    image_bgr = cv2.cvtColor(image_bgr, cv2.COLOR_RGB2BGR)\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(image_bgr, updated_bboxes, plate_number_gt)\n",
    "\n",
    "    if (alpha, beta) not in psnr_dict_avg:\n",
    "        psnr_dict_avg[(alpha, beta)] = []\n",
    "        ssim_dict_avg[(alpha, beta)] = []\n",
    "        ocr_acc_dict_avg[(alpha, beta)] = []\n",
    "        ocr_bin_dict_avg[(alpha, beta)] = []\n",
    "\n",
    "    psnr_dict_avg[(alpha, beta)].append(avg_psnr)\n",
    "    ssim_dict_avg[(alpha, beta)].append(avg_ssim)\n",
    "    ocr_acc_dict_avg[(alpha, beta)].append(ocr_accuracy)\n",
    "    ocr_bin_dict_avg[(alpha, beta)].append(ocr_binary)\n",
    "\n",
    "# Average if multiple images per angle (if any)\n",
    "for key in psnr_dict_avg:\n",
    "    psnr_dict_avg[key] = np.mean(psnr_dict_avg[key])\n",
    "    ssim_dict_avg[key] = np.mean(ssim_dict_avg[key])\n",
    "    ocr_acc_dict_avg[key] = np.mean(ocr_acc_dict_avg[key])\n",
    "    ocr_bin_dict_avg[key] = np.mean(ocr_bin_dict_avg[key])\n",
    "\n",
    "alpha_values = sorted(set(a for (a, b) in psnr_dict_avg.keys()))\n",
    "beta_values = sorted(set(b for (a, b) in psnr_dict_avg.keys()))\n",
    "num_alphas, num_betas = len(alpha_values), len(beta_values)\n",
    "\n",
    "def create_matrix_from_dict(data_dict):\n",
    "    mat = np.full((num_betas, num_alphas), np.nan)\n",
    "    alpha_to_idx = {val: i for i, val in enumerate(alpha_values)}\n",
    "    beta_to_idx = {val: i for i, val in enumerate(beta_values)}\n",
    "    for (a, b), val in data_dict.items():\n",
    "        mat[beta_to_idx[b], alpha_to_idx[a]] = val\n",
    "    return mat\n",
    "\n",
    "psnr_matrix_avg = create_matrix_from_dict(psnr_dict_avg)\n",
    "ssim_matrix_avg = create_matrix_from_dict(ssim_dict_avg)\n",
    "ocr_acc_matrix = create_matrix_from_dict(ocr_acc_dict_avg)\n",
    "ocr_bin_matrix = create_matrix_from_dict(ocr_bin_dict_avg)\n",
    "\n",
    "# -----------------------------------\n",
    "# Interactive Plot with Buttons\n",
    "# -----------------------------------\n",
    "current_metric = 'PSNR'\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plt.subplots_adjust(bottom=0.2)  # space for buttons\n",
    "\n",
    "im = ax.imshow(psnr_matrix_avg, origin='lower', aspect='auto', cmap=\"viridis\")\n",
    "ax.set_title(\"Average PSNR per Digit\")\n",
    "cb = plt.colorbar(im, ax=ax, label='PSNR (dB)')\n",
    "ax.set_xticks(range(0, num_alphas, 5))\n",
    "ax.set_xticklabels(alpha_values[::5])\n",
    "ax.set_yticks(range(0, num_betas, 5))\n",
    "ax.set_yticklabels(beta_values[::5])\n",
    "ax.set_xlabel(\"Alpha (degrees)\")\n",
    "ax.set_ylabel(\"Beta (degrees)\")\n",
    "\n",
    "def format_coord(x, y):\n",
    "    col = int(round(x))\n",
    "    row = int(round(y))\n",
    "    if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "        alpha = alpha_values[col]\n",
    "        beta = beta_values[row]\n",
    "        if current_metric == 'PSNR':\n",
    "            val = psnr_matrix_avg[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, PSNR: {val:.2f} dB\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'SSIM':\n",
    "            val = ssim_matrix_avg[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, SSIM: {val:.3f}\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'OCR_Accuracy':\n",
    "            val = ocr_acc_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, OCR Acc: {val*100:.2f}%\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'OCR_Binary':\n",
    "            val = ocr_bin_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, OCR Binary: {val:.0f}\" if not np.isnan(val) else \"N/A\"\n",
    "    return \"N/A\"\n",
    "\n",
    "ax.format_coord = format_coord\n",
    "\n",
    "def show_image_details_for(alpha, beta):\n",
    "    # Re-run the detailed view logic\n",
    "    # Find the file again\n",
    "    found_file = None\n",
    "    for meta_file in metadata_files:\n",
    "        meta_path = os.path.join(data_dir, meta_file)\n",
    "        with open(meta_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        if metadata['alpha'] == alpha and metadata['beta'] == beta:\n",
    "            found_file = metadata\n",
    "            break\n",
    "\n",
    "    if found_file is None:\n",
    "        print(\"No images found for that angle.\")\n",
    "        return\n",
    "\n",
    "    found_file['digit_bboxes'].sort(key=lambda bbox: bbox[0])\n",
    "    idx = found_file['idx']\n",
    "    plate_number_gt = found_file['plate_number']\n",
    "    original_path = os.path.join(data_dir, f\"original_{idx}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{idx}.png\")\n",
    "\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        reconstructed_tensor = model(distorted_img)\n",
    "        reconstructed_tensor = torch.clamp(reconstructed_tensor, 0.0, 1.0)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    reconstructed_np = reconstructed_tensor.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    psnr_vals, ssim_vals, updated_bboxes = align_and_update_bboxes(original_np, reconstructed_np, found_file['digit_bboxes'])\n",
    "\n",
    "    reconstructed_bgr = (reconstructed_np*255).astype(np.uint8)\n",
    "    reconstructed_bgr = cv2.cvtColor(reconstructed_bgr, cv2.COLOR_RGB2BGR)\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(reconstructed_bgr, updated_bboxes, plate_number_gt)\n",
    "\n",
    "    original_image_cv = cv2.imread(original_path)\n",
    "    for i, bbox in enumerate(found_file['digit_bboxes'], start=1):\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(original_image_cv, (x, y), (x+w, y+h), (0,0,255),1)\n",
    "        cv2.putText(original_image_cv, str(i), (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,150,0),1)\n",
    "    original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    reconstructed_show = reconstructed_bgr.copy()\n",
    "    for i,bbox in enumerate(updated_bboxes, start=1):\n",
    "        x,y,w,h = bbox\n",
    "        cv2.rectangle(reconstructed_show, (x,y),(x+w,y+h),(0,0,255),1)\n",
    "        cv2.putText(reconstructed_show,str(i),(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,150,0),1)\n",
    "    reconstructed_image_rgb = cv2.cvtColor(reconstructed_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    table_data = [[\"Digit\",\"PSNR(dB)\",\"SSIM\"]]\n",
    "    for i,(p,s) in enumerate(zip(psnr_vals, ssim_vals), start=1):\n",
    "        table_data.append([str(i), f\"{p:.2f}\", f\"{s:.3f}\"])\n",
    "    transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "    fig2 = plt.figure(figsize=(14,7))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(original_image_rgb)\n",
    "    plt.title(f'Original Image (Alpha={alpha}, Beta={beta})')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.imshow(reconstructed_image_rgb)\n",
    "    plt.title(f'Reconstructed Image\\nGT: {plate_number_gt}, Rec: {recognized_text}, OCR Acc: {ocr_accuracy*100:.2f}%, Binary: {ocr_binary}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    table = plt.table(cellText=transposed_table_data,\n",
    "                      cellLoc='center',\n",
    "                      loc='center',\n",
    "                      bbox=[0,-0.55,1,0.4])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def on_click(event):\n",
    "    if event.inaxes == ax:\n",
    "        x, y = event.xdata, event.ydata\n",
    "        if x is None or y is None:\n",
    "            return\n",
    "        col = int(round(x))\n",
    "        row = int(round(y))\n",
    "        if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "            alpha = alpha_values[col]\n",
    "            beta = beta_values[row]\n",
    "            show_image_details_for(alpha, beta)\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "# Add buttons to switch between metrics\n",
    "ax_psnr = plt.axes([0.1, 0.05, 0.1, 0.05])\n",
    "ax_ssim = plt.axes([0.22, 0.05, 0.1, 0.05])\n",
    "ax_ocr_acc = plt.axes([0.34, 0.05, 0.12, 0.05])\n",
    "ax_ocr_bin = plt.axes([0.48, 0.05, 0.1, 0.05])\n",
    "\n",
    "btn_psnr = Button(ax_psnr, 'PSNR')\n",
    "btn_ssim = Button(ax_ssim, 'SSIM')\n",
    "btn_ocr_acc = Button(ax_ocr_acc, 'OCR Acc')\n",
    "btn_ocr_bin = Button(ax_ocr_bin, 'OCR Bin')\n",
    "\n",
    "def update_heatmap(metric):\n",
    "    global current_metric\n",
    "    current_metric = metric\n",
    "    ax.clear()\n",
    "    if metric == 'PSNR':\n",
    "        data = psnr_matrix_avg\n",
    "        title = \"Average PSNR per Digit\"\n",
    "        cbar_label = \"PSNR (dB)\"\n",
    "    elif metric == 'SSIM':\n",
    "        data = ssim_matrix_avg\n",
    "        title = \"Average SSIM per Digit\"\n",
    "        cbar_label = \"SSIM\"\n",
    "    elif metric == 'OCR_Accuracy':\n",
    "        data = ocr_acc_matrix\n",
    "        title = \"Average OCR Accuracy\"\n",
    "        cbar_label = \"OCR Acc\"\n",
    "    else:\n",
    "        data = ocr_bin_matrix\n",
    "        title = \"OCR Binary (1=All Correct)\"\n",
    "        cbar_label = \"OCR Binary\"\n",
    "\n",
    "    im = ax.imshow(data, origin='lower', aspect='auto', cmap='viridis')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(0,num_alphas,5))\n",
    "    ax.set_xticklabels(alpha_values[::5])\n",
    "    ax.set_yticks(range(0,num_betas,5))\n",
    "    ax.set_yticklabels(beta_values[::5])\n",
    "    ax.set_xlabel(\"Alpha (degrees)\")\n",
    "    ax.set_ylabel(\"Beta (degrees)\")\n",
    "    ax.format_coord = format_coord\n",
    "    fig.colorbar(im, ax=ax, label=cbar_label)\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "def on_psnr_clicked(event):\n",
    "    update_heatmap('PSNR')\n",
    "\n",
    "def on_ssim_clicked(event):\n",
    "    update_heatmap('SSIM')\n",
    "\n",
    "def on_ocr_acc_clicked(event):\n",
    "    update_heatmap('OCR_Accuracy')\n",
    "\n",
    "def on_ocr_bin_clicked(event):\n",
    "    update_heatmap('OCR_Binary')\n",
    "\n",
    "btn_psnr.on_clicked(on_psnr_clicked)\n",
    "btn_ssim.on_clicked(on_ssim_clicked)\n",
    "btn_ocr_acc.on_clicked(on_ocr_acc_clicked)\n",
    "btn_ocr_bin.on_clicked(on_ocr_bin_clicked)\n",
    "\n",
    "current_metric = 'PSNR'  # default\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap Visualization of worst PSNR, worst SSIM, and OCR Metrics with Interactive Analysis\n",
    "\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import cv2\n",
    "from pytorch_msssim import ssim\n",
    "import pytesseract\n",
    "\n",
    "# --------------------\n",
    "# Configuration\n",
    "# --------------------\n",
    "data_dir = \"data/full_grid\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MLflow model load\n",
    "mlflow.set_experiment('Unet')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name('Unet')\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "run_id = runs[0].info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval().to(device)\n",
    "print(f\"Model loaded from run {run_id} in experiment '{experiment.name}' successfully.\")\n",
    "\n",
    "# --------------------\n",
    "# Functions \n",
    "# --------------------\n",
    "\n",
    "def calculate_psnr(outputs, targets):\n",
    "    mse = F.mse_loss(outputs, targets)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * torch.log10(1 / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "def align_and_update_bboxes(original_np, generated_np, digit_bboxes):\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "    updated_bboxes = []\n",
    "    search_margin = 10\n",
    "\n",
    "    for bbox in digit_bboxes:\n",
    "        x, y, w, h = bbox\n",
    "        original_digit = original_np[y:y+h, x:x+w, :]\n",
    "        original_digit_gray = cv2.cvtColor((original_digit * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Define search window\n",
    "        search_x1 = max(0, x - search_margin)\n",
    "        search_y1 = max(0, y - search_margin)\n",
    "        search_x2 = min(generated_np.shape[1], x + w + search_margin)\n",
    "        search_y2 = min(generated_np.shape[0], y + h + search_margin)\n",
    "        search_region = generated_np[search_y1:search_y2, search_x1:search_x2, :]\n",
    "        search_region_gray = cv2.cvtColor((search_region * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Template matching\n",
    "        result = cv2.matchTemplate(search_region_gray, original_digit_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        best_x, best_y = max_loc[0] + search_x1, max_loc[1] + search_y1\n",
    "        updated_bboxes.append((best_x, best_y, w, h))\n",
    "\n",
    "        # Compute PSNR and SSIM\n",
    "        aligned_digit = generated_np[best_y:best_y+h, best_x:best_x+w, :]\n",
    "        original_digit_tensor = torch.from_numpy(original_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "        aligned_digit_tensor = torch.from_numpy(aligned_digit.transpose(2,0,1)).unsqueeze(0).to(device)\n",
    "\n",
    "        psnr_val = calculate_psnr(aligned_digit_tensor, original_digit_tensor)\n",
    "        ssim_val = ssim(aligned_digit_tensor, original_digit_tensor, data_range=1.0, size_average=True).item()\n",
    "        psnr_values.append(psnr_val)\n",
    "        ssim_values.append(ssim_val)\n",
    "\n",
    "    return psnr_values, ssim_values, updated_bboxes\n",
    "\n",
    "def ocr_single_digit(image_bgr):\n",
    "    \"\"\"\n",
    "    Recognize a single digit using Tesseract with single char mode and digit whitelist.\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    config = r'--oem 1 --psm 10 -c tessedit_char_whitelist=0123456789'\n",
    "    text = pytesseract.image_to_string(thresh, config=config).strip()\n",
    "    if len(text) == 1 and text.isdigit():\n",
    "        return text\n",
    "    return '?'\n",
    "\n",
    "def compute_ocr_metrics(image_bgr, updated_bboxes, plate_number_gt, margin):\n",
    "    recognized_digits = []\n",
    "    for (x, y, w, h) in updated_bboxes:\n",
    "        x1 = max(0, x - margin)\n",
    "        y1 = max(0, y - margin)\n",
    "        x2 = min(image_bgr.shape[1], x + w + margin)\n",
    "        y2 = min(image_bgr.shape[0], y + h + margin)\n",
    "        \n",
    "        digit_patch = image_bgr[y1:y2, x1:x2]\n",
    "        recognized_digit = ocr_single_digit(digit_patch)\n",
    "        recognized_digits.append(recognized_digit)\n",
    "\n",
    "    recognized_text = \"\".join(recognized_digits)\n",
    "    gt = plate_number_gt\n",
    "    correct_digits = sum(1 for a, b in zip(gt, recognized_text) if a == b)\n",
    "    ocr_accuracy = correct_digits / len(gt) if len(gt) > 0 else 0.0\n",
    "    ocr_binary = 1.0 if recognized_text == gt else 0.0\n",
    "    return recognized_text, ocr_accuracy, ocr_binary\n",
    "\n",
    "# --------------------------------------\n",
    "# Compute metrics for each (alpha, beta)\n",
    "# --------------------------------------\n",
    "metadata_files = [f for f in os.listdir(data_dir) if f.startswith('metadata_') and f.endswith('.json')]\n",
    "\n",
    "psnr_dict_worst = {}\n",
    "ssim_dict_worst = {}\n",
    "ocr_acc_dict_avg = {}\n",
    "ocr_bin_dict_avg = {}\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "for meta_file in tqdm(metadata_files, desc=\"Processing images\", unit=\"image\"):\n",
    "    meta_path = os.path.join(data_dir, meta_file)\n",
    "    with open(meta_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    alpha, beta = metadata['alpha'], metadata['beta']\n",
    "    digit_bboxes = metadata['digit_bboxes']\n",
    "    plate_number_gt = metadata['plate_number']\n",
    "\n",
    "    idx = metadata['idx']\n",
    "    original_path = os.path.join(data_dir, f\"original_{idx}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{idx}.png\")\n",
    "\n",
    "    if not (os.path.exists(original_path) and os.path.exists(distorted_path)):\n",
    "        continue\n",
    "\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_img = model(distorted_img)\n",
    "        generated_img = torch.clamp(generated_img, 0.0, 1.0)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    generated_np = generated_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    psnr_per_number, ssim_per_number, updated_bboxes = align_and_update_bboxes(original_np, generated_np, digit_bboxes)\n",
    "\n",
    "    # Take the worst (minimum) PSNR and SSIM values across all digits for this image\n",
    "    worst_psnr = np.min(psnr_per_number) if psnr_per_number else 0.0\n",
    "    worst_ssim = np.min(ssim_per_number) if ssim_per_number else 0.0\n",
    "\n",
    "    image_bgr = (generated_np * 255).astype(np.uint8)\n",
    "    image_bgr = cv2.cvtColor(image_bgr, cv2.COLOR_RGB2BGR)\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(image_bgr, updated_bboxes, plate_number_gt, margin = 2)\n",
    "\n",
    "    if (alpha, beta) not in psnr_dict_worst:\n",
    "        psnr_dict_worst[(alpha, beta)] = []\n",
    "        ssim_dict_worst[(alpha, beta)] = []\n",
    "        ocr_acc_dict_avg[(alpha, beta)] = []\n",
    "        ocr_bin_dict_avg[(alpha, beta)] = []\n",
    "\n",
    "    psnr_dict_worst[(alpha, beta)].append(worst_psnr)\n",
    "    ssim_dict_worst[(alpha, beta)].append(worst_ssim)\n",
    "    ocr_acc_dict_avg[(alpha, beta)].append(ocr_accuracy)\n",
    "    ocr_bin_dict_avg[(alpha, beta)].append(ocr_binary)\n",
    "\n",
    "alpha_values = sorted(set(a for (a, b) in psnr_dict_worst.keys()))\n",
    "beta_values = sorted(set(b for (a, b) in psnr_dict_worst.keys()))\n",
    "num_alphas, num_betas = len(alpha_values), len(beta_values)\n",
    "\n",
    "def create_matrix_from_dict(data_dict):\n",
    "    mat = np.full((num_betas, num_alphas), np.nan)\n",
    "    alpha_to_idx = {val: i for i, val in enumerate(alpha_values)}\n",
    "    beta_to_idx = {val: i for i, val in enumerate(beta_values)}\n",
    "    for (a, b), val_list  in data_dict.items():\n",
    "        val = np.min(val_list) if val_list else np.nan\n",
    "        mat[beta_to_idx[b], alpha_to_idx[a]] = val\n",
    "    return mat\n",
    "\n",
    "psnr_matrix = create_matrix_from_dict(psnr_dict_worst)\n",
    "ssim_matrix = create_matrix_from_dict(ssim_dict_worst)\n",
    "ocr_acc_matrix = create_matrix_from_dict(ocr_acc_dict_avg)\n",
    "ocr_bin_matrix = create_matrix_from_dict(ocr_bin_dict_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------\n",
    "# Interactive Plot with Buttons\n",
    "# -----------------------------------\n",
    "current_metric = 'PSNR'\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "plt.subplots_adjust(bottom=0.2)  # space for buttons\n",
    "\n",
    "im = ax.imshow(psnr_matrix, origin='lower', aspect='auto', cmap=\"viridis\")\n",
    "ax.set_title(\"Worst PSNR per Image (Minimum Digit PSNR)\")\n",
    "cb = plt.colorbar(im, ax=ax, label='PSNR (dB)')\n",
    "ax.set_xticks(range(0, num_alphas, 5))\n",
    "ax.set_xticklabels(alpha_values[::5])\n",
    "ax.set_yticks(range(0, num_betas, 5))\n",
    "ax.set_yticklabels(beta_values[::5])\n",
    "ax.set_xlabel(\"Alpha (degrees)\")\n",
    "ax.set_ylabel(\"Beta (degrees)\")\n",
    "\n",
    "def format_coord(x, y):\n",
    "    col = int(round(x))\n",
    "    row = int(round(y))\n",
    "    if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "        alpha = alpha_values[col]\n",
    "        beta = beta_values[row]\n",
    "        if current_metric == 'PSNR':\n",
    "            val = psnr_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, Worst PSNR: {val:.2f} dB\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'SSIM':\n",
    "            val = ssim_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, Worst SSIM: {val:.3f}\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'OCR_Accuracy':\n",
    "            val = ocr_acc_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, OCR Acc: {val*100:.2f}%\" if not np.isnan(val) else \"N/A\"\n",
    "        elif current_metric == 'OCR_Binary':\n",
    "            val = ocr_bin_matrix[row, col]\n",
    "            return f\"Alpha: {alpha}, Beta: {beta}, OCR Binary: {val:.0f}\" if not np.isnan(val) else \"N/A\"\n",
    "    return \"N/A\"\n",
    "\n",
    "ax.format_coord = format_coord\n",
    "\n",
    "def show_image_details_for(alpha, beta):\n",
    "    # Re-run the detailed view logic\n",
    "    found_file = None\n",
    "    for meta_file in metadata_files:\n",
    "        meta_path = os.path.join(data_dir, meta_file)\n",
    "        with open(meta_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        if metadata['alpha'] == alpha and metadata['beta'] == beta:\n",
    "            found_file = metadata\n",
    "            break\n",
    "\n",
    "    if found_file is None:\n",
    "        print(\"No images found for that angle.\")\n",
    "        return\n",
    "\n",
    "    found_file['digit_bboxes'].sort(key=lambda bbox: bbox[0])\n",
    "    idx = found_file['idx']\n",
    "    plate_number_gt = found_file['plate_number']\n",
    "    original_path = os.path.join(data_dir, f\"original_{idx}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{idx}.png\")\n",
    "\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_tensor = model(distorted_img)\n",
    "        generated_tensor = torch.clamp(generated_tensor, 0.0, 1.0)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    generated_np = generated_tensor.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    psnr_vals, ssim_vals, updated_bboxes = align_and_update_bboxes(original_np, generated_np, found_file['digit_bboxes'])\n",
    "\n",
    "    generated_bgr = (generated_np*255).astype(np.uint8)\n",
    "    generated_bgr = cv2.cvtColor(generated_bgr, cv2.COLOR_RGB2BGR)\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(generated_bgr, updated_bboxes, plate_number_gt, margin = 2)\n",
    "\n",
    "    original_image_cv = cv2.imread(original_path)\n",
    "    for i, bbox in enumerate(found_file['digit_bboxes'], start=1):\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(original_image_cv, (x, y), (x+w, y+h), (0,0,255),1)\n",
    "        cv2.putText(original_image_cv, str(i), (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,150,0),1)\n",
    "    original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    generated_show = generated_bgr.copy()\n",
    "    for i,bbox in enumerate(updated_bboxes, start=1):\n",
    "        x,y,w,h = bbox\n",
    "        cv2.rectangle(generated_show, (x,y),(x+w,y+h),(0,0,255),1)\n",
    "        cv2.putText(generated_show,str(i),(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,150,0),1)\n",
    "    generated_image_rgb = cv2.cvtColor(generated_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    table_data = [[\"Digit\",\"PSNR(dB)\",\"SSIM\"]]\n",
    "    for i,(p,s) in enumerate(zip(psnr_vals, ssim_vals), start=1):\n",
    "        table_data.append([str(i), f\"{p:.2f}\", f\"{s:.3f}\"])\n",
    "    transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "    fig2 = plt.figure(figsize=(14,7))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(original_image_rgb)\n",
    "    plt.title(f'Original Image (Alpha={alpha}, Beta={beta})')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.imshow(generated_image_rgb)\n",
    "    plt.title(f'Generated Image\\nGT: {plate_number_gt}, Rec: {recognized_text}, OCR Acc: {ocr_accuracy*100:.2f}%, Binary: {ocr_binary}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    table = plt.table(cellText=transposed_table_data,\n",
    "                      cellLoc='center',\n",
    "                      loc='center',\n",
    "                      bbox=[0,-0.55,1,0.4])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def on_click(event):\n",
    "    if event.inaxes == ax:\n",
    "        x, y = event.xdata, event.ydata\n",
    "        if x is None or y is None:\n",
    "            return\n",
    "        col = int(round(x))\n",
    "        row = int(round(y))\n",
    "        if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "            alpha = alpha_values[col]\n",
    "            beta = beta_values[row]\n",
    "            show_image_details_for(alpha, beta)\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', on_click)\n",
    "\n",
    "# Add buttons to switch between metrics\n",
    "ax_psnr = plt.axes([0.1, 0.05, 0.1, 0.05])\n",
    "ax_ssim = plt.axes([0.22, 0.05, 0.1, 0.05])\n",
    "ax_ocr_acc = plt.axes([0.34, 0.05, 0.12, 0.05])\n",
    "ax_ocr_bin = plt.axes([0.48, 0.05, 0.1, 0.05])\n",
    "\n",
    "btn_psnr = Button(ax_psnr, 'PSNR')\n",
    "btn_ssim = Button(ax_ssim, 'SSIM')\n",
    "btn_ocr_acc = Button(ax_ocr_acc, 'OCR Acc')\n",
    "btn_ocr_bin = Button(ax_ocr_bin, 'OCR Bin')\n",
    "\n",
    "def update_heatmap(metric):\n",
    "    global current_metric\n",
    "    current_metric = metric\n",
    "    ax.clear()\n",
    "    if metric == 'PSNR':\n",
    "        data = psnr_matrix\n",
    "        title = \"Worst PSNR per Image (Minimum Digit PSNR)\"\n",
    "        cbar_label = \"PSNR (dB)\"\n",
    "    elif metric == 'SSIM':\n",
    "        data = ssim_matrix\n",
    "        title = \"Worst SSIM per Image (Minimum Digit SSIM)\"\n",
    "        cbar_label = \"SSIM\"\n",
    "    elif metric == 'OCR_Accuracy':\n",
    "        data = ocr_acc_matrix\n",
    "        title = \"Average OCR Accuracy\"\n",
    "        cbar_label = \"OCR Acc\"\n",
    "    else:\n",
    "        data = ocr_bin_matrix\n",
    "        title = \"OCR Binary (1=All Correct)\"\n",
    "        cbar_label = \"OCR Binary\"\n",
    "\n",
    "    im = ax.imshow(data, origin='lower', aspect='auto', cmap='viridis')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(0,num_alphas,5))\n",
    "    ax.set_xticklabels(alpha_values[::5])\n",
    "    ax.set_yticks(range(0,num_betas,5))\n",
    "    ax.set_yticklabels(beta_values[::5])\n",
    "    ax.set_xlabel(\"Alpha (degrees)\")\n",
    "    ax.set_ylabel(\"Beta (degrees)\")\n",
    "    ax.format_coord = format_coord\n",
    "    fig.colorbar(im, ax=ax, label=cbar_label)\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "def on_psnr_clicked(event):\n",
    "    update_heatmap('PSNR')\n",
    "\n",
    "def on_ssim_clicked(event):\n",
    "    update_heatmap('SSIM')\n",
    "\n",
    "def on_ocr_acc_clicked(event):\n",
    "    update_heatmap('OCR_Accuracy')\n",
    "\n",
    "def on_ocr_bin_clicked(event):\n",
    "    update_heatmap('OCR_Binary')\n",
    "\n",
    "btn_psnr.on_clicked(on_psnr_clicked)\n",
    "btn_ssim.on_clicked(on_ssim_clicked)\n",
    "btn_ocr_acc.on_clicked(on_ocr_acc_clicked)\n",
    "btn_ocr_bin.on_clicked(on_ocr_bin_clicked)\n",
    "\n",
    "current_metric = 'PSNR'  # default\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Heatmap of worst PSNR, SSIM, and OCR in parallel\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Button\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import cv2\n",
    "from pytorch_msssim import ssim\n",
    "import pytesseract\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# --------------------\n",
    "# Configuration\n",
    "# --------------------\n",
    "data_dir = \"data/test\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MLflow model load\n",
    "mlflow.set_experiment('Unet')\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "experiment = client.get_experiment_by_name('Unet')\n",
    "runs = client.search_runs(\n",
    "    experiment_ids=experiment.experiment_id,\n",
    "    order_by=[\"attributes.start_time DESC\"],\n",
    "    max_results=1\n",
    ")\n",
    "run_id = runs[0].info.run_id\n",
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "model = mlflow.pytorch.load_model(model_uri)\n",
    "model.eval().to(device)\n",
    "print(f\"Model loaded from run {run_id} in experiment '{experiment.name}' successfully.\")\n",
    "\n",
    "# --------------------\n",
    "# Functions \n",
    "# --------------------\n",
    "\n",
    "def calculate_psnr(outputs, targets):\n",
    "    mse = F.mse_loss(outputs, targets)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    psnr = 10 * torch.log10(1 / mse)\n",
    "    return psnr.item()\n",
    "\n",
    "def ocr_single_digit(image_bgr):\n",
    "    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY)\n",
    "    config = r'--oem 1 --psm 10 -c tessedit_char_whitelist=0123456789'\n",
    "    text = pytesseract.image_to_string(thresh, config=config).strip()\n",
    "    if len(text) == 1 and text.isdigit():\n",
    "        return text\n",
    "    return '?'\n",
    "\n",
    "def align_and_update_bboxes(original_np, generated_np, digit_bboxes):\n",
    "    search_margin = 16\n",
    "\n",
    "    def process_digit_bbox(bbox):\n",
    "        x, y, w, h = bbox\n",
    "        original_digit = original_np[y:y+h, x:x+w, :]\n",
    "        original_digit_gray = cv2.cvtColor((original_digit * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Define search window\n",
    "        search_x1 = max(0, x - search_margin)\n",
    "        search_y1 = max(0, y - search_margin)\n",
    "        search_x2 = min(generated_np.shape[1], x + w + search_margin)\n",
    "        search_y2 = min(generated_np.shape[0], y + h + search_margin)\n",
    "        search_region = generated_np[search_y1:search_y2, search_x1:search_x2, :]\n",
    "        search_region_gray = cv2.cvtColor((search_region * 255).astype(np.uint8), cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Template matching\n",
    "        result = cv2.matchTemplate(search_region_gray, original_digit_gray, cv2.TM_CCOEFF_NORMED)\n",
    "        _, _, _, max_loc = cv2.minMaxLoc(result)\n",
    "        best_x, best_y = max_loc[0] + search_x1, max_loc[1] + search_y1\n",
    "\n",
    "        # Compute PSNR and SSIM\n",
    "        aligned_digit = generated_np[best_y:best_y+h, best_x:best_x+w, :]\n",
    "        original_digit_tensor = torch.from_numpy(original_digit.transpose(2,0,1)).unsqueeze(0)\n",
    "        aligned_digit_tensor = torch.from_numpy(aligned_digit.transpose(2,0,1)).unsqueeze(0)\n",
    "\n",
    "        psnr_val = calculate_psnr(aligned_digit_tensor, original_digit_tensor)\n",
    "        ssim_val = ssim(aligned_digit_tensor, original_digit_tensor, data_range=1.0, size_average=True).item()\n",
    "\n",
    "        return psnr_val, ssim_val, (best_x, best_y, w, h)\n",
    "\n",
    "    results = Parallel(n_jobs=-1)(delayed(process_digit_bbox)(bbox) for bbox in digit_bboxes)\n",
    "    psnr_values = [r[0] for r in results]\n",
    "    ssim_values = [r[1] for r in results]\n",
    "    updated_bboxes = [r[2] for r in results]\n",
    "\n",
    "    return psnr_values, ssim_values, updated_bboxes\n",
    "\n",
    "def compute_ocr_metrics(image_bgr, updated_bboxes, plate_number_gt, margin):\n",
    "    def process_bbox(bbox):\n",
    "        x, y, w, h = bbox\n",
    "        x1 = max(0, x - margin)\n",
    "        y1 = max(0, y - margin)\n",
    "        x2 = min(image_bgr.shape[1], x + w + margin)\n",
    "        y2 = min(image_bgr.shape[0], y + h + margin)\n",
    "        digit_patch = image_bgr[y1:y2, x1:x2]\n",
    "        recognized_digit = ocr_single_digit(digit_patch)\n",
    "        return recognized_digit\n",
    "\n",
    "    recognized_digits = Parallel(n_jobs=-1)(delayed(process_bbox)(bbox) for bbox in updated_bboxes)\n",
    "    recognized_text = \"\".join(recognized_digits)\n",
    "    gt = plate_number_gt\n",
    "    correct_digits = sum(1 for a, b in zip(gt, recognized_text) if a == b)\n",
    "    ocr_accuracy = correct_digits / len(gt) if len(gt) > 0 else 0.0\n",
    "    ocr_binary = 1.0 if recognized_text == gt else 0.0\n",
    "    return recognized_text, ocr_accuracy, ocr_binary\n",
    "\n",
    "# --------------------------------------\n",
    "# Compute metrics for each (alpha, beta)\n",
    "# --------------------------------------\n",
    "metadata_files = [f for f in os.listdir(data_dir) if f.startswith('metadata_') and f.endswith('.json')]\n",
    "\n",
    "psnr_dict_worst = {}\n",
    "ssim_dict_worst = {}\n",
    "ocr_acc_dict_avg = {}\n",
    "ocr_bin_dict_avg = {}\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "for meta_file in tqdm(metadata_files, desc=\"Processing images\", unit=\"image\"):\n",
    "    meta_path = os.path.join(data_dir, meta_file)\n",
    "    with open(meta_path, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "    alpha, beta = metadata['alpha'], metadata['beta']\n",
    "    digit_bboxes = metadata['digit_bboxes']\n",
    "    plate_number_gt = metadata['plate_number']\n",
    "\n",
    "    idx = metadata['idx']\n",
    "    original_path = os.path.join(data_dir, f\"original_{idx}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{idx}.png\")\n",
    "\n",
    "    if not (os.path.exists(original_path) and os.path.exists(distorted_path)):\n",
    "        continue\n",
    "\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_img = model(distorted_img)\n",
    "        generated_img = torch.clamp(generated_img, 0.0, 1.0)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    generated_np = generated_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    # Parallelized CPU operations\n",
    "    psnr_per_number, ssim_per_number, updated_bboxes = align_and_update_bboxes(original_np, generated_np, digit_bboxes)\n",
    "    image_bgr = (generated_np * 255).astype(np.uint8)\n",
    "    image_bgr = cv2.cvtColor(image_bgr, cv2.COLOR_RGB2BGR)\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(image_bgr, updated_bboxes, plate_number_gt, margin=2)\n",
    "\n",
    "    # Take worst PSNR and SSIM\n",
    "    worst_psnr = np.min(psnr_per_number) if psnr_per_number else 0.0\n",
    "    worst_ssim = np.min(ssim_per_number) if ssim_per_number else 0.0\n",
    "\n",
    "    if (alpha, beta) not in psnr_dict_worst:\n",
    "        psnr_dict_worst[(alpha, beta)] = []\n",
    "        ssim_dict_worst[(alpha, beta)] = []\n",
    "        ocr_acc_dict_avg[(alpha, beta)] = []\n",
    "        ocr_bin_dict_avg[(alpha, beta)] = []\n",
    "\n",
    "    psnr_dict_worst[(alpha, beta)].append(worst_psnr)\n",
    "    ssim_dict_worst[(alpha, beta)].append(worst_ssim)\n",
    "    ocr_acc_dict_avg[(alpha, beta)].append(ocr_accuracy)\n",
    "    ocr_bin_dict_avg[(alpha, beta)].append(ocr_binary)\n",
    "\n",
    "alpha_values = sorted(set(a for (a, b) in psnr_dict_worst.keys()))\n",
    "beta_values = sorted(set(b for (a, b) in psnr_dict_worst.keys()))\n",
    "num_alphas, num_betas = len(alpha_values), len(beta_values)\n",
    "\n",
    "def create_matrix_from_dict(data_dict):\n",
    "    mat = np.full((num_betas, num_alphas), np.nan)\n",
    "    alpha_to_idx = {val: i for i, val in enumerate(alpha_values)}\n",
    "    beta_to_idx = {val: i for i, val in enumerate(beta_values)}\n",
    "    for (a, b), val_list  in data_dict.items():\n",
    "        val = np.min(val_list) if val_list else np.nan\n",
    "        mat[beta_to_idx[b], alpha_to_idx[a]] = val\n",
    "    return mat\n",
    "\n",
    "psnr_matrix = create_matrix_from_dict(psnr_dict_worst)\n",
    "ssim_matrix = create_matrix_from_dict(ssim_dict_worst)\n",
    "ocr_acc_matrix = create_matrix_from_dict(ocr_acc_dict_avg)\n",
    "ocr_bin_matrix = create_matrix_from_dict(ocr_bin_dict_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_details_for(alpha, beta):\n",
    "    # Re-run the detailed view logic\n",
    "    found_file = None\n",
    "    for meta_file in metadata_files:\n",
    "        meta_path = os.path.join(data_dir, meta_file)\n",
    "        with open(meta_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        if metadata['alpha'] == alpha and metadata['beta'] == beta:\n",
    "            found_file = metadata\n",
    "            break\n",
    "\n",
    "    if found_file is None:\n",
    "        print(\"No images found for that angle.\")\n",
    "        return\n",
    "\n",
    "    found_file['digit_bboxes'].sort(key=lambda bbox: bbox[0])\n",
    "    idx = found_file['idx']\n",
    "    plate_number_gt = found_file['plate_number']\n",
    "    original_path = os.path.join(data_dir, f\"original_{idx}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{idx}.png\")\n",
    "\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_tensor = model(distorted_img)\n",
    "        generated_tensor = torch.clamp(generated_tensor, 0.0, 1.0)\n",
    "\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    generated_np = generated_tensor.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    psnr_vals, ssim_vals, updated_bboxes = align_and_update_bboxes(original_np, generated_np, found_file['digit_bboxes'])\n",
    "\n",
    "    generated_bgr = (generated_np*255).astype(np.uint8)\n",
    "    generated_bgr = cv2.cvtColor(generated_bgr, cv2.COLOR_RGB2BGR)\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(generated_bgr, updated_bboxes, plate_number_gt, margin = 2)\n",
    "\n",
    "    original_image_cv = cv2.imread(original_path)\n",
    "    for i, bbox in enumerate(found_file['digit_bboxes'], start=1):\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(original_image_cv, (x, y), (x+w, y+h), (0,0,255),1)\n",
    "        cv2.putText(original_image_cv, str(i), (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,150,0),1)\n",
    "    original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    generated_show = generated_bgr.copy()\n",
    "    for i,bbox in enumerate(updated_bboxes, start=1):\n",
    "        x,y,w,h = bbox\n",
    "        cv2.rectangle(generated_show, (x,y),(x+w,y+h),(0,0,255),1)\n",
    "        cv2.putText(generated_show,str(i),(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,150,0),1)\n",
    "    generated_image_rgb = cv2.cvtColor(generated_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    table_data = [[\"Digit\",\"PSNR(dB)\",\"SSIM\"]]\n",
    "    for i,(p,s) in enumerate(zip(psnr_vals, ssim_vals), start=1):\n",
    "        table_data.append([str(i), f\"{p:.2f}\", f\"{s:.3f}\"])\n",
    "    transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "    fig2 = plt.figure(figsize=(14,7))\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(original_image_rgb)\n",
    "    plt.title(f'Original Image (Alpha={alpha}, Beta={beta})')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.imshow(generated_image_rgb)\n",
    "    plt.title(f'Generated Image\\nGT: {plate_number_gt}, Rec: {recognized_text}, OCR Acc: {ocr_accuracy*100:.2f}%, Binary: {ocr_binary}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    table = plt.table(cellText=transposed_table_data,\n",
    "                      cellLoc='center',\n",
    "                      loc='center',\n",
    "                      bbox=[0,-0.55,1,0.4])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "psnr_matrix_clipped = np.clip(psnr_matrix, None, 20)\n",
    "\n",
    "current_metric = 'PSNR'\n",
    "fig, ax = plt.subplots(figsize=(11, 9))\n",
    "plt.subplots_adjust(bottom=0.15)  # space for buttons\n",
    "\n",
    "# Draw initial heatmap\n",
    "im = ax.imshow(psnr_matrix_clipped, origin='lower', aspect='auto', cmap=\"viridis\")\n",
    "ax.set_title(\"Worst PSNR per Image (Minimum Digit PSNR)\")\n",
    "cbar = plt.colorbar(im, ax=ax, label='PSNR (dB)')\n",
    "ax.set_xticks(range(0, num_alphas, 5))\n",
    "ax.set_xticklabels(alpha_values[::5])\n",
    "ax.set_yticks(range(0, num_betas, 5))\n",
    "ax.set_yticklabels(beta_values[::5])\n",
    "ax.set_xlabel(\"Alpha (degrees)\")\n",
    "ax.set_ylabel(\"Beta (degrees)\")\n",
    "ax.format_coord = format_coord  # Set the coordinate display format\n",
    "\n",
    "# Define button positions\n",
    "button_width = 0.1   # Button width\n",
    "button_height = 0.05  # Button height\n",
    "button_spacing = 0.02  # Space between buttons\n",
    "\n",
    "# Compute x-coordinates for buttons\n",
    "x_start = 0.2  # Starting x-position\n",
    "y_position = 0.03\n",
    "x_psnr = x_start\n",
    "x_ssim = x_psnr + button_width + button_spacing\n",
    "x_ocr_acc = x_ssim + button_width + button_spacing\n",
    "x_ocr_bin = x_ocr_acc + button_width + button_spacing\n",
    "\n",
    "# Add buttons\n",
    "ax_psnr = plt.axes([x_psnr, y_position, button_width, button_height])\n",
    "ax_ssim = plt.axes([x_ssim, y_position, button_width, button_height])\n",
    "ax_ocr_acc = plt.axes([x_ocr_acc, y_position, button_width, button_height])\n",
    "ax_ocr_bin = plt.axes([x_ocr_bin, y_position, button_width, button_height])\n",
    "\n",
    "btn_psnr = Button(ax_psnr, 'PSNR')\n",
    "btn_ssim = Button(ax_ssim, 'SSIM')\n",
    "btn_ocr_acc = Button(ax_ocr_acc, 'OCR Acc')\n",
    "btn_ocr_bin = Button(ax_ocr_bin, 'OCR Bin')\n",
    "\n",
    "def update_heatmap(metric):\n",
    "    global current_metric\n",
    "    current_metric = metric\n",
    "    ax.clear()\n",
    "    \n",
    "    if metric == 'PSNR':\n",
    "        data = psnr_matrix_clipped\n",
    "        title = \"Worst PSNR per Image (Minimum Digit PSNR)\"\n",
    "        cbar_label = \"PSNR (dB)\"\n",
    "    elif metric == 'SSIM':\n",
    "        data = ssim_matrix\n",
    "        title = \"Worst SSIM per Image (Minimum Digit SSIM)\"\n",
    "        cbar_label = \"SSIM\"\n",
    "    elif metric == 'OCR_Accuracy':\n",
    "        data = ocr_acc_matrix\n",
    "        title = \"Average OCR Accuracy\"\n",
    "        cbar_label = \"OCR Acc\"\n",
    "    else:\n",
    "        data = ocr_bin_matrix\n",
    "        title = \"OCR Binary (1=All Correct)\"\n",
    "        cbar_label = \"OCR Binary\"\n",
    "\n",
    "    # Update heatmap\n",
    "    im = ax.imshow(data, origin='lower', aspect='auto', cmap='viridis')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(0, num_alphas, 5))\n",
    "    ax.set_xticklabels(alpha_values[::5])\n",
    "    ax.set_yticks(range(0, num_betas, 5))\n",
    "    ax.set_yticklabels(beta_values[::5])\n",
    "    ax.set_xlabel(\"Alpha (degrees)\")\n",
    "    ax.set_ylabel(\"Beta (degrees)\")\n",
    "\n",
    "    # Update colorbar\n",
    "    cbar.mappable = im\n",
    "    cbar.set_label(cbar_label)\n",
    "    cbar.update_normal(im)\n",
    "\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "def on_psnr_clicked(event):\n",
    "    update_heatmap('PSNR')\n",
    "\n",
    "def on_ssim_clicked(event):\n",
    "    update_heatmap('SSIM')\n",
    "\n",
    "def on_ocr_acc_clicked(event):\n",
    "    update_heatmap('OCR_Accuracy')\n",
    "\n",
    "def on_ocr_bin_clicked(event):\n",
    "    update_heatmap('OCR_Binary')\n",
    "\n",
    "btn_psnr.on_clicked(on_psnr_clicked)\n",
    "btn_ssim.on_clicked(on_ssim_clicked)\n",
    "btn_ocr_acc.on_clicked(on_ocr_acc_clicked)\n",
    "btn_ocr_bin.on_clicked(on_ocr_bin_clicked)\n",
    "\n",
    "# Connect the click event after setting up the entire figure\n",
    "def on_click(event):\n",
    "    if event.inaxes == ax:  # Ensure the click is within the heatmap axis\n",
    "        x, y = event.xdata, event.ydata\n",
    "        if x is None or y is None:\n",
    "            return\n",
    "        col = int(round(x))\n",
    "        row = int(round(y))\n",
    "        if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "            alpha = alpha_values[col]\n",
    "            beta = beta_values[row]\n",
    "            show_image_details_for(alpha, beta)\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', on_click)  # Connect after all setups\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def show_image_details_for(alpha, beta):\n",
    "    # Re-run the detailed view logic\n",
    "    found_file = None\n",
    "    for meta_file in metadata_files:\n",
    "        meta_path = os.path.join(data_dir, meta_file)\n",
    "        with open(meta_path, 'r') as f:\n",
    "            metadata = json.load(f)\n",
    "        if metadata['alpha'] == alpha and metadata['beta'] == beta:\n",
    "            found_file = metadata\n",
    "            break\n",
    "\n",
    "    if found_file is None:\n",
    "        print(\"No images found for that angle.\")\n",
    "        return\n",
    "\n",
    "    found_file['digit_bboxes'].sort(key=lambda bbox: bbox[0])\n",
    "    idx = found_file['idx']\n",
    "    plate_number_gt = found_file['plate_number']\n",
    "    original_path = os.path.join(data_dir, f\"original_{idx}.png\")\n",
    "    distorted_path = os.path.join(data_dir, f\"distorted_{idx}.png\")\n",
    "\n",
    "    # Load images as tensors for generation\n",
    "    original_img = to_tensor(Image.open(original_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    distorted_img = to_tensor(Image.open(distorted_path).convert('RGB')).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        generated_tensor = model(distorted_img)\n",
    "        generated_tensor = torch.clamp(generated_tensor, 0.0, 1.0)\n",
    "\n",
    "    # Convert tensors to numpy arrays\n",
    "    original_np = original_img.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "    generated_np = generated_tensor.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "    # Compute PSNR, SSIM, and bounding boxes\n",
    "    psnr_vals, ssim_vals, updated_bboxes = align_and_update_bboxes(original_np, generated_np, found_file['digit_bboxes'])\n",
    "\n",
    "    # Prepare images for display\n",
    "    distorted_image_cv = cv2.imread(distorted_path)\n",
    "    distorted_image_rgb = cv2.cvtColor(distorted_image_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Original image (with rectangles and text)\n",
    "    original_image_cv = cv2.imread(original_path)\n",
    "    for i, bbox in enumerate(found_file['digit_bboxes'], start=1):\n",
    "        x, y, w, h = bbox\n",
    "        cv2.rectangle(original_image_cv, (x, y), (x+w, y+h), (0,0,255),1)\n",
    "        cv2.putText(original_image_cv, str(i), (x,y-5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,(0,150,0),1)\n",
    "    original_image_rgb = cv2.cvtColor(original_image_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Generated image (with rectangles and text)\n",
    "    generated_bgr = (generated_np * 255).astype(np.uint8)\n",
    "    generated_bgr = cv2.cvtColor(generated_bgr, cv2.COLOR_RGB2BGR)  \n",
    "    generated_show = generated_bgr.copy()\n",
    "    for i,bbox in enumerate(updated_bboxes, start=1):\n",
    "        x,y,w,h = bbox\n",
    "        cv2.rectangle(generated_show, (x,y),(x+w,y+h),(0,0,255),1)\n",
    "        cv2.putText(generated_show,str(i),(x,y-5),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,150,0),1)\n",
    "    generated_image_rgb = cv2.cvtColor(generated_show, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    recognized_text, ocr_accuracy, ocr_binary = compute_ocr_metrics(generated_bgr, updated_bboxes, plate_number_gt, margin=2)\n",
    "\n",
    "    # Prepare table data\n",
    "    table_data = [[\"Digit\",\"PSNR(dB)\",\"SSIM\"]]\n",
    "    for i,(p,s) in enumerate(zip(psnr_vals, ssim_vals), start=1):\n",
    "        table_data.append([str(i), f\"{p:.2f}\", f\"{s:.3f}\"])\n",
    "    transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "    # Create figure with 3 rows: Distorted, Original, Generated\n",
    "    fig2 = plt.figure(figsize=(11,9))\n",
    "\n",
    "    # Distorted image \n",
    "    plt.subplot(3,1,1)\n",
    "    plt.imshow(distorted_image_rgb)\n",
    "    plt.title(f'Distorted Image (Alpha={alpha}, Beta={beta})')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Original image \n",
    "    plt.subplot(3,1,2)\n",
    "    plt.imshow(original_image_rgb)\n",
    "    plt.title(f'Original Image')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Generated image \n",
    "    plt.subplot(3,1,3)\n",
    "    plt.imshow(generated_image_rgb)\n",
    "    plt.title(f'Generated Image\\nGT: {plate_number_gt}, Rec: {recognized_text}, OCR Acc: {ocr_accuracy*100:.2f}%, Binary: {int(ocr_binary)}')\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Add table below all images\n",
    "    # Adjust the bbox so it appears below the last subplot\n",
    "    table = plt.table(cellText=transposed_table_data,\n",
    "                      cellLoc='center',\n",
    "                      loc='center',\n",
    "                      bbox=[0,-0.5, 1,0.4])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def format_coord(x, y):\n",
    "    col = int(round(x))\n",
    "    row = int(round(y))\n",
    "    if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "        alpha = alpha_values[col]\n",
    "        beta = beta_values[row]\n",
    "        psnr_value = psnr_matrix_clipped[row, col]\n",
    "        return f\"Alpha: {alpha:.0f}, Beta: {beta:.0f}, PSNR: {psnr_value:.2f} dB\" if not np.isnan(psnr_value) else f\"Alpha: {alpha:.0f}, Beta: {beta:.0f}, PSNR: N/A\"\n",
    "    return \"Alpha: N/A, Beta: N/A\"\n",
    "\n",
    "psnr_matrix_clipped = np.clip(psnr_matrix, None, 20)\n",
    "\n",
    "current_metric = 'PSNR'\n",
    "fig, ax = plt.subplots(figsize=(11, 9))\n",
    "plt.subplots_adjust(bottom=0.15)  # space for buttons\n",
    "\n",
    "# Draw initial heatmap\n",
    "im = ax.imshow(psnr_matrix_clipped, origin='lower', aspect='auto', cmap=\"viridis\")\n",
    "ax.set_title(\"Worst PSNR per Image (Minimum Digit PSNR)\")\n",
    "cbar = plt.colorbar(im, ax=ax, label='PSNR (dB)')\n",
    "ax.set_xticks(range(0, num_alphas, 5))\n",
    "ax.set_xticklabels(alpha_values[::5])\n",
    "ax.set_yticks(range(0, num_betas, 5))\n",
    "ax.set_yticklabels(beta_values[::5])\n",
    "ax.set_xlabel(\"Alpha (degrees)\")\n",
    "ax.set_ylabel(\"Beta (degrees)\")\n",
    "ax.format_coord = format_coord  # Set the coordinate display format\n",
    "\n",
    "# Define button positions\n",
    "button_width = 0.1   # Button width\n",
    "button_height = 0.05  # Button height\n",
    "button_spacing = 0.02  # Space between buttons\n",
    "\n",
    "# Compute x-coordinates for buttons\n",
    "x_start = 0.2  # Starting x-position\n",
    "y_position = 0.03\n",
    "x_psnr = x_start\n",
    "x_ssim = x_psnr + button_width + button_spacing\n",
    "x_ocr_acc = x_ssim + button_width + button_spacing\n",
    "x_ocr_bin = x_ocr_acc + button_width + button_spacing\n",
    "\n",
    "# Add buttons\n",
    "ax_psnr = plt.axes([x_psnr, y_position, button_width, button_height])\n",
    "ax_ssim = plt.axes([x_ssim, y_position, button_width, button_height])\n",
    "ax_ocr_acc = plt.axes([x_ocr_acc, y_position, button_width, button_height])\n",
    "ax_ocr_bin = plt.axes([x_ocr_bin, y_position, button_width, button_height])\n",
    "\n",
    "btn_psnr = Button(ax_psnr, 'PSNR')\n",
    "btn_ssim = Button(ax_ssim, 'SSIM')\n",
    "btn_ocr_acc = Button(ax_ocr_acc, 'OCR Acc')\n",
    "btn_ocr_bin = Button(ax_ocr_bin, 'OCR Bin')\n",
    "\n",
    "def update_heatmap(metric):\n",
    "    global current_metric\n",
    "    current_metric = metric\n",
    "    ax.clear()\n",
    "    \n",
    "    if metric == 'PSNR':\n",
    "        data = psnr_matrix_clipped\n",
    "        title = \"Worst PSNR per Image (Minimum Digit PSNR)\"\n",
    "        cbar_label = \"PSNR (dB)\"\n",
    "    elif metric == 'SSIM':\n",
    "        data = ssim_matrix\n",
    "        title = \"Worst SSIM per Image (Minimum Digit SSIM)\"\n",
    "        cbar_label = \"SSIM\"\n",
    "    elif metric == 'OCR_Accuracy':\n",
    "        data = ocr_acc_matrix\n",
    "        title = \"OCR Accuracy\"\n",
    "        cbar_label = \"OCR Acc\"\n",
    "    else:\n",
    "        data = ocr_bin_matrix\n",
    "        title = \"OCR Binary Accuracy (1=All Correct)\"\n",
    "        cbar_label = \"OCR Binary\"\n",
    "\n",
    "    # Update heatmap\n",
    "    im = ax.imshow(data, origin='lower', aspect='auto', cmap='viridis')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(range(0, num_alphas, 5))\n",
    "    ax.set_xticklabels(alpha_values[::5])\n",
    "    ax.set_yticks(range(0, num_betas, 5))\n",
    "    ax.set_yticklabels(beta_values[::5])\n",
    "    ax.set_xlabel(\"Alpha (degrees)\")\n",
    "    ax.set_ylabel(\"Beta (degrees)\")\n",
    "\n",
    "    # Update colorbar\n",
    "    cbar.mappable = im\n",
    "    cbar.set_label(cbar_label)\n",
    "    cbar.update_normal(im)\n",
    "\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "def on_psnr_clicked(event):\n",
    "    update_heatmap('PSNR')\n",
    "\n",
    "def on_ssim_clicked(event):\n",
    "    update_heatmap('SSIM')\n",
    "\n",
    "def on_ocr_acc_clicked(event):\n",
    "    update_heatmap('OCR_Accuracy')\n",
    "\n",
    "def on_ocr_bin_clicked(event):\n",
    "    update_heatmap('OCR_Binary')\n",
    "\n",
    "btn_psnr.on_clicked(on_psnr_clicked)\n",
    "btn_ssim.on_clicked(on_ssim_clicked)\n",
    "btn_ocr_acc.on_clicked(on_ocr_acc_clicked)\n",
    "btn_ocr_bin.on_clicked(on_ocr_bin_clicked)\n",
    "\n",
    "# Connect the click event after setting up the entire figure\n",
    "def on_click(event):\n",
    "    if event.inaxes == ax:  # Ensure the click is within the heatmap axis\n",
    "        x, y = event.xdata, event.ydata\n",
    "        if x is None or y is None:\n",
    "            return\n",
    "        col = int(round(x))\n",
    "        row = int(round(y))\n",
    "        if 0 <= row < num_betas and 0 <= col < num_alphas:\n",
    "            alpha = alpha_values[col]\n",
    "            beta = beta_values[row]\n",
    "            show_image_details_for(alpha, beta)\n",
    "\n",
    "cid = fig.canvas.mpl_connect('button_press_event', on_click)  # Connect after all setups\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lpr_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
