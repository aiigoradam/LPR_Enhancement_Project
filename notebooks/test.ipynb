{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "# # Get the current working directory and image path\n",
    "# project_dir = os.getcwd()\n",
    "\n",
    "# Get the current working directory and move one directory up\n",
    "project_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Construct the image path from the project directory\n",
    "image_path = os.path.join(project_dir, \"data_unique\", \"Original_2.png\")\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Preprocess the image (if necessary)\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Apply thresholding to make the image binary\n",
    "_, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Configure Tesseract to recognize digits only and output symbol-level data\n",
    "custom_config = r'--oem 3 --psm 8 -c tessedit_char_whitelist=0123456789'\n",
    "\n",
    "# Perform OCR with detailed data output at the symbol level\n",
    "data = pytesseract.image_to_data(thresh, config=custom_config, output_type=pytesseract.Output.DICT)\n",
    "\n",
    "# Extract character-level details\n",
    "recognized_chars = []\n",
    "\n",
    "n_boxes = len(data['text'])\n",
    "for i in range(n_boxes):\n",
    "    text = data['text'][i].strip()\n",
    "    if text.isdigit():\n",
    "        recognized_chars.append(text)\n",
    "# Print the recognized digits\n",
    "print(\"Recognized Digits:\")\n",
    "for char in recognized_chars:\n",
    "    print(f\"Number: {char}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from pytorch_msssim import ssim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_psnr_ssim_per_number(original_image_path, distorted_image_path, digit_bboxes):\n",
    "    \"\"\"\n",
    "    Calculates PSNR and SSIM for each digit in the license plate using the bounding boxes with PyTorch.\n",
    "\n",
    "    Args:\n",
    "        original_image_path (str): Path to the original image.\n",
    "        distorted_image_path (str): Path to the distorted image.\n",
    "        digit_bboxes (list of tuples): List of bounding boxes for each digit [(x1, y1, w, h), ...].\n",
    "\n",
    "    Returns:\n",
    "        tuple: Two lists containing PSNR and SSIM values for each digit.\n",
    "    \"\"\"\n",
    "    # Load images\n",
    "    transform = transforms.ToTensor()\n",
    "    original_image = transform(Image.open(original_image_path).convert(\"RGB\"))\n",
    "    distorted_image = transform(Image.open(distorted_image_path).convert(\"RGB\"))\n",
    "\n",
    "    psnr_values = []\n",
    "    ssim_values = []\n",
    "\n",
    "    for bbox in digit_bboxes:\n",
    "        x, y, w, h = map(int, bbox)  # Ensure coordinates are integers\n",
    "        x2, y2 = x + w, y + h\n",
    "\n",
    "        # Extract regions\n",
    "        original_region = original_image[:, y:y2, x:x2].unsqueeze(0)  # Add batch dimension\n",
    "        distorted_region = distorted_image[:, y:y2, x:x2].unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "        # PSNR Calculation\n",
    "        mse = F.mse_loss(original_region, distorted_region)\n",
    "        psnr_value = 10 * torch.log10(1.0 / mse)\n",
    "\n",
    "        psnr_values.append(psnr_value.item())  # Convert to Python float\n",
    "\n",
    "        # SSIM Calculation\n",
    "        ssim_value = ssim(distorted_region, original_region, data_range=1.0, size_average=True)\n",
    "        ssim_values.append(ssim_value.item())  # Convert to Python float\n",
    "\n",
    "    return psnr_values, ssim_values\n",
    "\n",
    "\n",
    "# Get the current working directory and image path\n",
    "index = 2\n",
    "# project_dir = os.getcwd()\n",
    "project_dir = os.path.dirname(os.getcwd())\n",
    "original_image_path = os.path.join(project_dir, f\"data_unique/original_{index}.png\")\n",
    "distorted_image_path = os.path.join(project_dir, f\"data_unique/distorted_{index}.png\")\n",
    "metadata_path = os.path.join(project_dir, f\"data_unique/metadata_{index}.json\")\n",
    "\n",
    "# Load metadata to get digit_bboxes\n",
    "with open(metadata_path, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "digit_bboxes = metadata['digit_bboxes']\n",
    "\n",
    "# Show the distorted and the original image with bounding boxes in red\n",
    "original_image = cv2.imread(original_image_path)\n",
    "distorted_image = cv2.imread(distorted_image_path)\n",
    "\n",
    "for bbox in digit_bboxes:\n",
    "    x, y, w, h = bbox\n",
    "    cv2.rectangle(original_image, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "    cv2.rectangle(distorted_image, (x, y), (x + w, y + h), (0, 0, 255), 1)\n",
    "\n",
    "# Calculate PSNR per number\n",
    "psnr_per_number, ssim_per_number = calculate_psnr_ssim_per_number(\n",
    "    original_image_path, distorted_image_path, digit_bboxes)\n",
    "\n",
    "# Prepare data for the table\n",
    "table_data = [[\"Digit\", \"PSNR(dB)\", \"SSIM\"]]\n",
    "for i, (psnr, ssim) in enumerate(zip(psnr_per_number, ssim_per_number), start=1):\n",
    "    table_data.append([str(i), f\"{psnr:.2f}\", f\"{ssim:.3f}\"])\n",
    "\n",
    "# Transpose the table data\n",
    "transposed_table_data = list(zip(*table_data))\n",
    "\n",
    "# Display the images using pyplot\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Original Image\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Distorted Image\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(cv2.cvtColor(distorted_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Distorted Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Adjust the layout to make room for the table\n",
    "plt.subplots_adjust(left=0.3, bottom=0.3, top=0.95)\n",
    "\n",
    "# Add the transposed table below the images\n",
    "table = plt.table(cellText=transposed_table_data,\n",
    "                  colLabels=None,\n",
    "                  cellLoc='center',\n",
    "                  loc='bottom',\n",
    "                  bbox=[0, -0.5, 1, 0.4])  # [left, bottom, width, height]\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1, 1)\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lpr_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
